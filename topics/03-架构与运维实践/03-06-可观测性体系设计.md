# 3.6 可观测性体系设计

## 目录

- [3.6 可观测性体系设计](#36-可观测性体系设计)
  - [目录](#目录)
  - [3.6.1 可观测性三大支柱](#361-可观测性三大支柱)
    - [Metrics（指标）](#metrics指标)
    - [Logging（日志）](#logging日志)
    - [Tracing（链路追踪）](#tracing链路追踪)
  - [3.6.2 Kafka可观测性设计](#362-kafka可观测性设计)
  - [3.6.3 MQTT可观测性设计](#363-mqtt可观测性设计)
  - [3.6.4 NATS可观测性设计](#364-nats可观测性设计)
  - [3.6.5 可观测性工具链](#365-可观测性工具链)
  - [3.6.6 可观测性最佳实践](#366-可观测性最佳实践)

---

## 3.6.1 可观测性三大支柱

### Metrics（指标）

**指标类型**：

| 指标类型 | 说明 | 示例 |
|---------|------|------|
| **Counter（计数器）** | 单调递增的数值 | 消息总数、错误总数 |
| **Gauge（仪表盘）** | 可增可减的数值 | 当前连接数、内存使用率 |
| **Histogram（直方图）** | 数值分布统计 | 延迟分布、消息大小分布 |
| **Summary（摘要）** | 分位数统计 | P50/P95/P99延迟 |

**Golden Signals（黄金信号）**：

1. **Latency（延迟）**: 请求处理时间
2. **Traffic（流量）**: 系统负载
3. **Errors（错误）**: 错误率
4. **Saturation（饱和度）**: 资源使用率

**参考**: [The Four Golden Signals - Google SRE](https://sre.google/sre-book/monitoring-distributed-systems/)

### Logging（日志）

**日志级别**：

- **DEBUG**: 调试信息，开发环境使用
- **INFO**: 一般信息，记录正常流程
- **WARN**: 警告信息，需要关注但不影响功能
- **ERROR**: 错误信息，功能异常但系统可继续运行
- **FATAL**: 致命错误，系统无法继续运行

**结构化日志**：

```json
{
  "timestamp": "2025-12-31T10:00:00Z",
  "level": "INFO",
  "service": "kafka-producer",
  "trace_id": "abc123",
  "message": "Message sent successfully",
  "metadata": {
    "topic": "orders",
    "partition": 0,
    "offset": 12345
  }
}
```

**日志聚合架构**：

```
应用 → Log Agent (Filebeat/Fluentd) → Log Storage (ELK/Loki) → Log Analysis (Kibana/Grafana)
```

### Tracing（链路追踪）

**分布式追踪概念**：

- **Trace**: 一次完整的请求链路
- **Span**: 链路中的一个操作
- **Span Context**: 跨服务传递的上下文信息

**OpenTelemetry标准**：

```python
# Python示例
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.jaeger import JaegerExporter

trace.set_tracer_provider(TracerProvider())
tracer = trace.get_tracer(__name__)

exporter = JaegerExporter(agent_host_name="localhost", agent_port=6831)
span_processor = BatchSpanProcessor(exporter)
trace.get_tracer_provider().add_span_processor(span_processor)

# 创建Span
with tracer.start_as_current_span("kafka-produce") as span:
    span.set_attribute("topic", "orders")
    span.set_attribute("partition", 0)
    # 发送消息
    producer.send("orders", "message")
```

**参考**: [OpenTelemetry Documentation](https://opentelemetry.io/docs/)

## 3.6.2 Kafka可观测性设计

### Metrics指标

**JMX指标导出**：

```properties
# server.properties
jmx.port=9999
```

**Prometheus Exporter配置**：

```yaml
# kafka-jmx-exporter.yml
rules:
  - pattern: kafka.server<type=(.+), name=(.+)><>Value
    name: kafka_server_$1_$2
    type: GAUGE

  - pattern: kafka.network<type=RequestMetrics, name=(.+), request=(.+)><>Count
    name: kafka_network_request_$1_$2_total
    type: COUNTER
```

**关键指标**：

```yaml
kafka_metrics:
  # 吞吐量指标
  throughput:
    - kafka_server_BrokerTopicMetrics_MessagesInPerSec
    - kafka_server_BrokerTopicMetrics_BytesInPerSec
    - kafka_server_BrokerTopicMetrics_BytesOutPerSec

  # 延迟指标
  latency:
    - kafka_network_RequestMetrics_TotalTimeMs{request="Produce"}
    - kafka_network_RequestMetrics_TotalTimeMs{request="Fetch"}

  # 副本指标
  replication:
    - kafka_server_ReplicaManager_UnderReplicatedPartitions
    - kafka_server_ReplicaManager_IsrShrinksPerSec

  # Consumer Lag
  consumer_lag:
    - kafka_consumer_lag_sum
    - kafka_consumer_lag_max
```

### Logging日志

**日志配置**：

```properties
# log4j.properties
log4j.rootLogger=INFO, stdout, kafkaAppender

log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=[%d] %p %m (%c)%n

log4j.appender.kafkaAppender=org.apache.log4j.RollingFileAppender
log4j.appender.kafkaAppender.File=/var/log/kafka/server.log
log4j.appender.kafkaAppender.MaxFileSize=100MB
log4j.appender.kafkaAppender.MaxBackupIndex=10
log4j.appender.kafkaAppender.layout=org.apache.log4j.PatternLayout
log4j.appender.kafkaAppender.layout.ConversionPattern=[%d] %p %m (%c)%n
```

**结构化日志示例**：

```json
{
  "timestamp": "2025-12-31T10:00:00Z",
  "level": "INFO",
  "logger": "kafka.server.KafkaServer",
  "message": "Starting Kafka server",
  "broker_id": 1,
  "version": "3.5.0"
}
```

### Tracing链路追踪

**Kafka客户端集成OpenTelemetry**：

```java
// Java示例
import io.opentelemetry.api.trace.Tracer;
import io.opentelemetry.api.trace.Span;

Tracer tracer = OpenTelemetry.getGlobalTracer("kafka-client");

Span span = tracer.spanBuilder("kafka-produce")
    .setAttribute("messaging.system", "kafka")
    .setAttribute("messaging.destination", "orders")
    .startSpan();

try (Scope scope = span.makeCurrent()) {
    producer.send(new ProducerRecord<>("orders", "key", "value"));
} finally {
    span.end();
}
```

## 3.6.3 MQTT可观测性设计

### Metrics指标

**MQTT Broker指标**：

```yaml
mqtt_metrics:
  # 连接指标
  connections:
    - mqtt_connections_total
    - mqtt_connections_active
    - mqtt_connections_max

  # 消息指标
  messages:
    - mqtt_messages_received_total
    - mqtt_messages_sent_total
    - mqtt_messages_dropped_total

  # QoS指标
  qos:
    - mqtt_qos0_messages_total
    - mqtt_qos1_messages_total
    - mqtt_qos2_messages_total
    - mqtt_qos2_pending_messages

  # 订阅指标
  subscriptions:
    - mqtt_subscriptions_total
    - mqtt_subscriptions_active
```

**EMQX指标导出**：

```yaml
# emqx.conf
prometheus {
  enable = true
  push_gateway_server = "http://localhost:9091"
  interval = 15s
}
```

### Logging日志

**MQTT日志格式**：

```json
{
  "timestamp": "2025-12-31T10:00:00Z",
  "level": "INFO",
  "client_id": "device-123",
  "event": "client.connected",
  "ip_address": "192.168.1.100",
  "port": 1883,
  "protocol": "mqtt",
  "version": "5.0"
}
```

### Tracing链路追踪

**MQTT消息追踪**：

```python
# Python示例
from opentelemetry import trace
from opentelemetry.instrumentation.mqtt import MQTTInstrumentor

# 自动注入追踪
MQTTInstrumentor().instrument()

# 发布消息时自动创建Span
client.publish("home/sensor/temperature", "25.5", qos=1)
```

## 3.6.4 NATS可观测性设计

### Metrics指标

**NATS内置监控端点**：

```bash
# 监控端点
curl http://localhost:8222/varz    # 变量统计
curl http://localhost:8222/connz   # 连接信息
curl http://localhost:8222/subsz   # 订阅信息
curl http://localhost:8222/routez  # 路由信息
```

**Prometheus指标导出**：

```yaml
# nats-server.conf
http_port: 8222

# Prometheus指标
varz: true
connz: true
subsz: true
routez: true
```

**关键指标**：

```yaml
nats_metrics:
  # 连接指标
  connections:
    - nats_connections
    - nats_connections_max
    - nats_connections_closed

  # 消息指标
  messages:
    - nats_in_msgs
    - nats_out_msgs
    - nats_in_bytes
    - nats_out_bytes

  # 订阅指标
  subscriptions:
    - nats_subscriptions
    - nats_slow_consumers

  # 路由指标
  routes:
    - nats_routes
    - nats_remotes
```

### Logging日志

**NATS日志配置**：

```conf
# nats-server.conf
log_file: "/var/log/nats/nats.log"
log_time: true
log_debug: false
log_trace: false
log_colors: false
```

**结构化日志示例**：

```json
{
  "timestamp": "2025-12-31T10:00:00Z",
  "level": "INFO",
  "message": "Client connection created",
  "client_id": "client-123",
  "ip": "192.168.1.100",
  "port": 4222
}
```

### Tracing链路追踪

**NATS客户端集成OpenTelemetry**：

```go
// Go示例
import (
    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/trace"
)

tracer := otel.Tracer("nats-client")

ctx, span := tracer.Start(ctx, "nats-publish",
    trace.WithAttributes(
        attribute.String("messaging.system", "nats"),
        attribute.String("messaging.destination", "events"),
    ),
)
defer span.End()

nc.Publish("events", []byte("data"))
```

## 3.6.5 可观测性工具链

### Metrics工具

| 工具 | 类型 | 特点 | 适用场景 |
|------|------|------|----------|
| **Prometheus** | 时序数据库 | 拉取模式、PromQL查询 | 云原生、Kubernetes |
| **InfluxDB** | 时序数据库 | 推送模式、SQL-like查询 | IoT、高频指标 |
| **Grafana** | 可视化 | 丰富的图表、告警 | 所有场景 |
| **VictoriaMetrics** | 时序数据库 | Prometheus兼容、高性能 | 大规模指标 |

### Logging工具

| 工具 | 类型 | 特点 | 适用场景 |
|------|------|------|----------|
| **ELK Stack** | 日志聚合 | Elasticsearch+Logstash+Kibana | 企业级日志分析 |
| **Loki** | 日志聚合 | 轻量级、Grafana集成 | 云原生、Kubernetes |
| **Fluentd** | 日志收集 | 插件丰富、云原生 | 容器化环境 |
| **Filebeat** | 日志收集 | 轻量级、Elastic集成 | 日志文件收集 |

### Tracing工具

| 工具 | 类型 | 特点 | 适用场景 |
|------|------|------|----------|
| **Jaeger** | 分布式追踪 | CNCF项目、OpenTracing | 微服务追踪 |
| **Zipkin** | 分布式追踪 | 简单易用、社区活跃 | 中小型系统 |
| **Tempo** | 分布式追踪 | Grafana集成、对象存储 | 云原生环境 |
| **SkyWalking** | APM | 全链路追踪、性能分析 | Java生态 |

### 统一可观测性平台

**架构设计**：

```
应用层
  ↓
OpenTelemetry SDK (Metrics/Logs/Traces)
  ↓
Collector (OTel Collector)
  ↓
存储层
  ├─ Prometheus (Metrics)
  ├─ Loki (Logs)
  └─ Tempo (Traces)
  ↓
可视化层
  └─ Grafana (统一Dashboard)
```

## 3.6.6 可观测性最佳实践

### 1. 指标设计原则

- **USE方法**: Utilization（使用率）、Saturation（饱和度）、Errors（错误）
- **RED方法**: Rate（速率）、Errors（错误）、Duration（持续时间）
- **Golden Signals**: Latency、Traffic、Errors、Saturation

### 2. 日志设计原则

- **结构化日志**: 使用JSON格式，便于解析和查询
- **日志级别**: 合理使用DEBUG/INFO/WARN/ERROR
- **敏感信息**: 避免记录密码、Token等敏感信息
- **日志采样**: 高频日志使用采样，避免存储压力

### 3. 追踪设计原则

- **采样率**: 生产环境使用1-10%采样率
- **Trace ID**: 在日志和指标中关联Trace ID
- **Span命名**: 使用有意义的Span名称
- **属性记录**: 记录关键业务属性

### 4. 告警设计原则

- **告警疲劳**: 避免过多告警，使用告警聚合
- **告警级别**: Critical/Warning/Info三级告警
- **告警规则**: 基于SLO/SLA设定告警阈值
- **告警响应**: 定义清晰的告警响应流程

---

## 3.6.7 可观测性参考资源

### 理论参考

- **可观测性工程**: [Observability Engineering](https://www.oreilly.com/library/view/observability-engineering/9781492076438/)
- **Google SRE**: [Site Reliability Engineering](https://sre.google/sre-book/table-of-contents/)
- **OpenTelemetry**: [OpenTelemetry Documentation](https://opentelemetry.io/docs/)

### 工具参考

- **Prometheus**: [Prometheus Documentation](https://prometheus.io/docs/)
- **Grafana**: [Grafana Documentation](https://grafana.com/docs/)
- **Jaeger**: [Jaeger Documentation](https://www.jaegertracing.io/docs/)

---

**参考来源**:
- Google SRE实践和可观测性理论
- OpenTelemetry标准和最佳实践
- Prometheus、Grafana等工具文档
- 生产环境可观测性实践

**最后更新**: 2025-12-31
