# 3.5 异常监控与自动恢复

## 目录

- [3.5 异常监控与自动恢复](#35-异常监控与自动恢复)
  - [目录](#目录)
  - [3.5.1 异常监控体系](#351-异常监控体系)
    - [监控指标设计](#监控指标设计)
    - [告警规则设计](#告警规则设计)
    - [监控工具选择](#监控工具选择)
  - [3.5.2 自动恢复机制](#352-自动恢复机制)
    - [Kafka自动恢复](#kafka自动恢复)
    - [MQTT自动恢复](#mqtt自动恢复)
    - [NATS自动恢复](#nats自动恢复)
  - [3.5.3 故障自愈系统](#353-故障自愈系统)
    - [自愈策略设计](#自愈策略设计)
    - [自愈流程设计](#自愈流程设计)
    - [自愈效果评估](#自愈效果评估)
  - [3.5.4 异常处理自动化](#354-异常处理自动化)
    - [自动化工具](#自动化工具)
  - [3.5.5 异常监控参考资源](#355-异常监控参考资源)
    - [监控理论参考](#监控理论参考)
    - [工具参考](#工具参考)

---

## 3.5.1 异常监控体系

### 监控指标设计

**Kafka监控指标**：

```yaml
# Kafka关键监控指标
kafka_metrics:
  # 可用性指标
  broker_availability:
    - name: "BrokerUp"
      type: "gauge"
      threshold: "== 1"
      severity: "critical"

  # 性能指标
  performance:
    - name: "MessagesInPerSec"
      type: "rate"
      threshold: "< 1000"
      severity: "warning"
    - name: "BytesInPerSec"
      type: "rate"
      threshold: "< 100MB/s"
      severity: "warning"

  # 可靠性指标
  reliability:
    - name: "UnderReplicatedPartitions"
      type: "gauge"
      threshold: "> 0"
      severity: "critical"
    - name: "ISRShrinksPerSec"
      type: "rate"
      threshold: "> 10"
      severity: "warning"

  # 资源指标
  resources:
    - name: "DiskUsagePercent"
      type: "gauge"
      threshold: "> 80%"
      severity: "warning"
    - name: "JVMHeapUsagePercent"
      type: "gauge"
      threshold: "> 85%"
      severity: "warning"
```

**MQTT监控指标**：

```yaml
# MQTT关键监控指标
mqtt_metrics:
  # 连接指标
  connections:
    - name: "ConnectedClients"
      type: "gauge"
      threshold: "> 80% max_connections"
      severity: "warning"
    - name: "ConnectionRate"
      type: "rate"
      threshold: "> 100/sec"
      severity: "warning"

  # 消息指标
  messages:
    - name: "MessagesInPerSec"
      type: "rate"
      threshold: "< expected_rate * 0.9"
      severity: "warning"
    - name: "MessagesDropped"
      type: "counter"
      threshold: "> 0"
      severity: "critical"

  # QoS指标
  qos:
    - name: "QoS2PendingMessages"
      type: "gauge"
      threshold: "> 10000"
      severity: "warning"
    - name: "QoS2TimeoutRate"
      type: "rate"
      threshold: "> 1%"
      severity: "warning"
```

**NATS监控指标**：

```yaml
# NATS关键监控指标
nats_metrics:
  # 连接指标
  connections:
    - name: "Connections"
      type: "gauge"
      threshold: "> max_connections * 0.9"
      severity: "warning"
    - name: "SlowConsumers"
      type: "gauge"
      threshold: "> 10"
      severity: "warning"

  # 消息指标
  messages:
    - name: "InMsgs"
      type: "rate"
      threshold: "< expected_rate * 0.9"
      severity: "warning"
    - name: "OutMsgs"
      type: "rate"
      threshold: "< expected_rate * 0.9"
      severity: "warning"

  # 资源指标
  resources:
    - name: "Memory"
      type: "gauge"
      threshold: "> max_memory * 0.9"
      severity: "warning"
    - name: "PendingMsgs"
      type: "gauge"
      threshold: "> max_pending_msgs * 0.9"
      severity: "warning"
```

### 告警规则设计

**告警级别**：

- **Critical（严重）**: 服务不可用，需要立即处理
- **Warning（警告）**: 性能下降或异常，需要关注
- **Info（信息）**: 状态变化，记录即可

**告警规则示例**：

```yaml
# Prometheus告警规则
groups:
  - name: kafka_alerts
    rules:
      - alert: KafkaBrokerDown
        expr: kafka_server_kafkaserver_brokerstate{state="3"} == 1
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Kafka broker is down"
          description: "Broker {{ $labels.instance }} is down"

      - alert: KafkaUnderReplicatedPartitions
        expr: kafka_controller_offlinepartitionscount > 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Kafka has under-replicated partitions"
          description: "{{ $value }} partitions are under-replicated"

      - alert: KafkaHighConsumerLag
        expr: kafka_consumer_lag_sum > 10000
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Kafka consumer lag is high"
          description: "Consumer lag is {{ $value }} messages"
```

### 监控工具选择

| 工具 | Kafka | MQTT | NATS | 特点 |
|------|-------|------|------|------|
| **Prometheus** | ✅ 支持 | ✅ 支持 | ✅ 支持 | 开源，指标丰富 |
| **Grafana** | ✅ 支持 | ✅ 支持 | ✅ 支持 | 可视化强大 |
| **JMX** | ✅ 原生支持 | ❌ 不支持 | ❌ 不支持 | Kafka原生监控 |
| **内置监控** | ⚠️ 有限 | ⚠️ 有限 | ✅ 丰富 | NATS内置HTTP端点 |

## 3.5.2 自动恢复机制

### Kafka自动恢复

**自动恢复场景**：

```bash
#!/bin/bash
# Kafka自动恢复脚本

# 场景1: Broker宕机自动恢复
check_broker_health() {
    local broker=$1
    if ! nc -z $broker 9092; then
        echo "Broker $broker is down"

        # 检查是否是Controller
        if is_controller $broker; then
            echo "Controller is down, waiting for election"
            wait_for_controller_election
        fi

        # 检查分区状态
        check_partition_health

        # 等待ISR恢复
        wait_for_isr_recovery
    fi
}

# 场景2: 分区不均衡自动恢复
auto_rebalance_partitions() {
    local threshold=0.1  # 10%不均衡阈值

    if check_partition_imbalance > $threshold; then
        echo "Partition imbalance detected, triggering rebalance"
        kafka-reassign-partitions.sh \
            --bootstrap-server localhost:9092 \
            --reassignment-json-file reassignment.json \
            --execute
    fi
}

# 场景3: 磁盘满自动清理
auto_cleanup_logs() {
    local disk_usage=$(df -h /kafka-logs | awk 'NR==2 {print $5}' | sed 's/%//')

    if [ $disk_usage -gt 85 ]; then
        echo "Disk usage is ${disk_usage}%, cleaning old logs"

        # 减少保留时间
        kafka-configs.sh --alter \
            --entity-type topics \
            --entity-name all \
            --add-config retention.ms=86400000  # 1天

        # 触发日志清理
        kafka-log-retention.sh --delete-old-logs
    fi
}
```

### MQTT自动恢复

**自动恢复场景**：

```python
# MQTT自动恢复机制
class MQTTAutoRecovery:
    def __init__(self):
        self.broker_health_check_interval = 30  # 30秒检查一次
        self.max_failures = 3
        self.failure_count = 0

    def monitor_broker_health(self):
        """监控Broker健康状态"""
        while True:
            try:
                # 检查Broker连接
                if not self.check_broker_connection():
                    self.failure_count += 1

                    if self.failure_count >= self.max_failures:
                        # 触发故障转移
                        self.failover_to_backup()
                        self.failure_count = 0
                else:
                    self.failure_count = 0

                time.sleep(self.broker_health_check_interval)

            except Exception as e:
                log.error(f"Health check error: {e}")

    def failover_to_backup(self):
        """故障转移到备用Broker"""
        log.warn("Primary broker failed, failing over to backup")

        # 切换到备用Broker
        backup_broker = self.get_backup_broker()
        self.client.reconnect(backup_broker.host, backup_broker.port)

        # 恢复会话
        self.restore_sessions()

    def auto_scale_connections(self):
        """自动扩缩容连接"""
        current_connections = self.get_connection_count()
        max_connections = self.get_max_connections()

        if current_connections > max_connections * 0.9:
            # 连接数接近上限，扩容
            self.scale_up_brokers()
        elif current_connections < max_connections * 0.5:
            # 连接数较低，缩容
            self.scale_down_brokers()
```

### NATS自动恢复

**自动恢复场景**：

```go
// NATS自动恢复机制
func setupAutoRecovery(nc *nats.Conn) {
    // NATS内置自动恢复机制
    opts := []nats.Option{
        nats.MaxReconnects(-1),  // 无限重连
        nats.ReconnectWait(1 * time.Second),
        nats.ReconnectJitter(500*time.Millisecond, 2*time.Second),

        // 断开连接处理
        nats.DisconnectErrHandler(func(nc *nats.Conn, err error) {
            if err != nil {
                log.Printf("Disconnected: %v", err)
                // NATS会自动重连，无需手动处理
            }
        }),

        // 重连成功处理
        nats.ReconnectHandler(func(nc *nats.Conn) {
            log.Printf("Reconnected to %v", nc.ConnectedUrl())
            // 重连后自动恢复订阅
            restoreSubscriptions(nc)
        }),

        // 连接关闭处理
        nats.ClosedHandler(func(nc *nats.Conn) {
            log.Printf("Connection closed")
            // 可以触发告警或通知
        }),
    }

    nc, _ := nats.Connect("nats://localhost:4222", opts...)
}

func restoreSubscriptions(nc *nats.Conn) {
    // 恢复所有订阅
    // NATS客户端会自动恢复订阅，但可以手动重新订阅确保一致性
    subscriptions := getPreviousSubscriptions()
    for _, sub := range subscriptions {
        nc.Subscribe(sub.subject, sub.handler)
    }
}
```

## 3.5.3 故障自愈系统

### 自愈策略设计

**自愈策略矩阵**：

| 故障类型 | 检测方法 | 自愈动作 | 恢复时间 | 自动化程度 |
|---------|----------|----------|----------|-----------|
| **Broker宕机** | 健康检查 | 等待ISR恢复 | 30秒-2分钟 | 自动 |
| **磁盘满** | 磁盘监控 | 清理旧日志 | 1-5分钟 | 自动 |
| **内存溢出** | 内存监控 | 重启Broker | 2-5分钟 | 半自动 |
| **网络分区** | 网络监控 | 等待网络恢复 | 5-30分钟 | 自动 |
| **Consumer Lag高** | Lag监控 | 扩容Consumer | 5-10分钟 | 自动（K8s HPA） |

### 自愈流程设计

**自愈流程**：

```yaml
# 自愈流程定义
self_healing_workflow:
  - name: "BrokerDown"
    detection:
      - metric: "kafka_broker_up"
        condition: "== 0"
        duration: "1m"
    actions:
      - wait_for_isr_recovery:
          timeout: "5m"
      - check_partition_health:
          threshold: "all_partitions_healthy"
      - notify:
          level: "info"
          message: "Broker recovered automatically"

  - name: "HighConsumerLag"
    detection:
      - metric: "kafka_consumer_lag"
        condition: "> 10000"
        duration: "10m"
    actions:
      - scale_up_consumers:
          target_lag: "< 1000"
      - wait_for_lag_reduction:
          timeout: "10m"
      - verify:
          metric: "kafka_consumer_lag"
          condition: "< 1000"
```

### 自愈效果评估

**自愈成功率**：

| 系统 | 自愈成功率 | MTTR（自动） | MTTR（手动） | 效率提升 |
|------|-----------|-------------|-------------|----------|
| **Kafka** | 60% | 2分钟 | 30分钟 | 15倍 |
| **MQTT** | 70% | 3分钟 | 20分钟 | 6.7倍 |
| **NATS** | 95% | 5秒 | 10分钟 | 120倍 |

**自愈效果指标**：

- **MTTR（Mean Time To Repair）**: 平均恢复时间
- **MTBF（Mean Time Between Failures）**: 平均故障间隔时间
- **自愈成功率**: 自动恢复成功的比例
- **人工干预率**: 需要人工干预的比例

## 3.5.4 异常处理自动化

### 自动化工具

**Kubernetes Operator**：

```yaml
# Kafka Operator自动恢复配置
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    replicas: 3
    # 自动恢复配置
    readinessProbe:
      initialDelaySeconds: 30
      timeoutSeconds: 10
    livenessProbe:
      initialDelaySeconds: 60
      timeoutSeconds: 10
    # 自动扩缩容
    autoScaling:
      enabled: true
      minReplicas: 3
      maxReplicas: 10
      metrics:
        - type: ConsumerLag
          targetValue: "1000"
```

**Prometheus + Alertmanager自动恢复**：

```yaml
# Alertmanager自动恢复配置
route:
  routes:
    - match:
        alertname: KafkaBrokerDown
      receiver: 'auto-recovery'
      continue: true

receivers:
  - name: 'auto-recovery'
    webhook_configs:
      - url: 'http://auto-recovery-service:8080/recover'
        http_config:
          follow_redirects: true
```

---

## 3.5.5 异常监控参考资源

### 监控理论参考

- **SRE监控**: [Site Reliability Engineering - Monitoring](https://sre.google/sre-book/monitoring-distributed-systems/)
- **Golden Signals**: [The Four Golden Signals](https://sre.google/sre-book/monitoring-distributed-systems/)
- **SLI/SLO**: [Service Level Indicators](https://sre.google/workbook/sli-slo/)

### 工具参考

- **Prometheus**: [Prometheus Documentation](https://prometheus.io/docs/)
- **Grafana**: [Grafana Documentation](https://grafana.com/docs/)
- **Kubernetes Operators**: [Operator Pattern](https://kubernetes.io/docs/concepts/extend-kubernetes/operator/)

---

**参考来源**:

- 基于concept03.md内容整理
- Google SRE实践和监控理论
- Prometheus、Grafana等监控工具文档
- Kubernetes Operator模式和最佳实践

**最后更新**: 2025-12-31
