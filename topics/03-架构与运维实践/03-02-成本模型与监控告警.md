# 3.2 成本模型与监控告警

## 目录

- [3.2 成本模型与监控告警](#32-成本模型与监控告警)
  - [目录](#目录)
  - [3.2.1 成本模型对比（TCO）](#321-成本模型对比tco)
  - [3.2.2 监控告警设计矩阵](#322-监控告警设计矩阵)
    - [Kafka监控黄金指标](#kafka监控黄金指标)
    - [MQTT监控黄金指标](#mqtt监控黄金指标)
    - [NATS监控黄金指标](#nats监控黄金指标)
    - [Pulsar监控黄金指标](#pulsar监控黄金指标)
  - [3.2.3 SLO/SLA设定参考](#323-slosla设定参考)

---

## 3.2.1 成本模型对比（TCO）

| 成本项 | Kafka | MQTT | NATS Core | NATS JetStream | Pulsar | 运维影响分析 |
|--------|-------|------|-----------|----------------|--------|--------------|
| **基础设施** | 高<br/>(3×8核32GB+SSD) | 中<br/>(2×4核16GB) | **极低**<br/>(1×2核4GB) | 中<br/>(3×4核16GB+SSD) | **核心差异**：NATS Core内存占用<50MB，可在边缘设备运行 |
| **存储成本** | 高<br/>(0.5元/GB/月) | 低<br/>(仅会话) | 0 | 中<br/>(0.3元/GB/月) | Kafka需保留7天日志，10万TPS≈5TB/天 |
| **人力成本** | 高<br/>(需Kafka专家) | 中<br/>(MQTT协议理解) | **极低**<br/>(1人可运维) | 低<br/>(比Kafka简单) | **学习曲线**：Kafka配置参数>200个，NATS<20个 |
| **监控成本** | 高<br/>(ZK+Kafka+OS) | 中<br/>(MQTT+OS) | **极低**<br/>(内置监控) | 低 | NATS内置`/varz`/connz等HTTP监控端点，无需黑盒探针 |
| **升级成本** | 高<br/>(停机窗口+兼容性) | 中 | **极低**<br/>(滚动重启) | 低 | Kafka 0.10→3.0需跨版本兼容测试，NATS向后兼容 |
| **故障恢复** | 高<br/>(30分钟+) | 中<br/>(10分钟) | **极低**<br/>(秒级) | 低 | 中<br/>(5-10分钟) | Kafka Controller选举+分区重分配耗时，NATS客户端自动切换，Pulsar BookKeeper自动恢复 |
| **多租户支持** | 无 | 无 | 无 | 无 | **原生支持** | Pulsar原生多租户，无需额外配置 |
| **分层存储** | 无 | 无 | 无 | 无 | **原生支持** | Pulsar自动卸载冷数据，存储成本降低60% |

**TCO计算公式**：

```text
总成本 = 基础设施×3年 + 人力成本×3年 + 监控工具成本 + 故障损失期望值

故障损失期望值 = P(故障)×RTO×业务损失率

其中：
- Kafka: P(故障)=5%/年, RTO=30分钟
- NATS: P(故障)=2%/年, RTO=1分钟
- MQTT: P(故障)=3%/年, RTO=15分钟
- Pulsar: P(故障)=3%/年, RTO=10分钟（但多租户场景下TCO更低）

结论：在100万日活场景下，NATS 3年TCO比Kafka低40-60%；在多租户SaaS场景下，Pulsar 3年TCO比Kafka低30-50%（考虑多租户和分层存储优势）
```

**实际案例数据**（基于生产环境调研）：

| 公司规模 | Kafka 3年TCO | NATS 3年TCO | MQTT 3年TCO | Pulsar 3年TCO | 节省比例 |
|---------|--------------|-------------|-------------|--------------|----------|
| **小型**（10万日活） | 50-80万 | 20-30万 | 30-50万 | 40-60万 | NATS节省60% |
| **中型**（100万日活） | 200-300万 | 80-120万 | 150-200万 | 140-180万 | NATS节省55%，Pulsar节省30%（多租户场景） |
| **大型**（1000万日活） | 1000-1500万 | 400-600万 | 800-1000万 | 700-900万 | NATS节省50%，Pulsar节省40%（多租户+分层存储） |

**成本构成分析**（中型规模，100万日活）：

**Kafka成本构成**：

- 基础设施：120万（6台Broker + 3台ZK，3年）
- 人力成本：90万（1名Kafka专家，3年）
- 监控工具：30万（Confluent Control Center或自建）
- 故障损失：60万（5%故障率×30分钟RTO）
- **总计：300万**

**NATS成本构成**：

- 基础设施：30万（3台Server，3年）
- 人力成本：30万（1名运维，3年）
- 监控工具：10万（内置监控+Prometheus）
- 故障损失：10万（2%故障率×1分钟RTO）
- **总计：80万**

**参考数据来源**：

- [Confluent TCO Calculator](https://www.confluent.io/pricing/)
- [NATS Resource Usage Documentation](https://docs.nats.io/running-a-nats-service/nats_admin/resource_usage)
- 行业调研和实际部署案例

## 3.2.2 监控告警设计矩阵

### Kafka监控黄金指标

```yaml
# 架构层级监控
infrastructure:
  - disk_io_util:  # 磁盘IO等待时间
      threshold: ">70%"
      action: 扩容磁盘或增加Broker
  - network_latency:  # 副本同步延迟
      threshold: ">50ms"
      action: 检查网络分区或调整replica.fetch.wait.max.ms

kafka_cluster:
  - UnderReplicatedPartitions:  # 欠副本分区
      threshold: ">0"
      severity: critical
      action: 立即检查Broker存活状态和磁盘空间
  - ISRShrinkRate:  # ISR收缩速率
      threshold: ">10/min"
      action: 调整replica.lag.time.max.ms或扩容
  - ActiveControllerCount:  # 活跃Controller数
      threshold: "!=1"
      severity: critical
      action: 检查ZooKeeper连通性

application:
  - ConsumerLag:  # 消费延迟
      threshold: ">10000"
      action: 增加Consumer实例或优化消费逻辑
  - RequestHandlerAvgIdlePercent:  # Broker空闲率
      threshold: "<20%"
      action: 增加Broker节点
```

**运维痛点**：

1. **ZK依赖**：需额外监控ZK集群的Znode数量和延迟
2. **分区重分配**：扩容后需手动执行`kafka-reassign-partitions.sh`，耗时数小时
3. **Broker不均衡**：需定期运行`kafka-preferred-replica-election`平衡Leader

### MQTT监控黄金指标

```yaml
broker:
  - connected_clients:  # 当前连接数
      threshold: ">80% max_connections"
      action: 增加Broker节点或调整max_connections
  - message_drop_rate:  # 消息丢弃率
      threshold: ">0.1%"
      severity: warning
      action: 检查QoS配置和存储空间

session:
  - persistent_sessions:  # 持久会话数
      threshold: ">100k"
      action: 增加共享存储容量或清理过期会话
  - subscription_count:  # 订阅主题数
      threshold: ">1M"
      action: 优化主题设计，避免单主题订阅过多

device:
  - keepalive_timeout:  # 心跳超时率
      threshold: ">5%"
      action: 调整keepalive间隔或网络质量
```

**运维痛点**：

1. **会话风暴**：设备批量重连时，Broker会话恢复压力巨大
2. **主题泛滥**：设备动态主题导致内存占用不可控
3. **QoS2性能**：QoS2四步握手在高并发下吞吐量下降70%

### NATS监控黄金指标

```yaml
server:
  - routes:  # 集群路由数
      threshold: "<expected_nodes-1"
      severity: critical
      action: 检查网络分区或节点宕机
  - slow_consumers:  # 慢消费者数量
      threshold: ">10"
      action: 增加消费者处理能力或调整max_pending_msgs
  - memory_usage:  # 内存占用
      threshold: ">80%"
      action: 限制最大连接数或增加节点

jetstream:
  - raft_leader_changes:  # Raft leader变更
      threshold: ">5/hour"
      action: 检查网络稳定性
  - stream_stalled:  # 流是否停滞
      threshold: "true"
      severity: critical
      action: 检查磁盘空间或消费者ACK情况

# NATS内置监控端点，无需额外Agent
# curl http://nats-server:8222/varz
```

**运维优势**：

1. **内生监控**：启动即暴露HTTP监控接口，无需黑盒探针
2. **自愈能力**：客户端自动重连，无需人工干预
3. **配置极简**：无复杂参数，默认配置即生产就绪

### Pulsar监控黄金指标

```yaml
broker:
  - broker_load_balancer_enabled:  # Broker负载均衡状态
      threshold: "false"
      severity: warning
      action: 启用负载均衡或检查Broker状态
  - active_connections:  # 活跃连接数
      threshold: ">80% max_connections"
      action: 增加Broker节点或调整max_connections
  - message_publish_rate:  # 消息发布速率
      threshold: ">80% capacity"
      action: 增加Broker节点或优化Producer

bookkeeper:
  - bookie_failures:  # Bookie故障数
      threshold: ">0"
      severity: critical
      action: 检查Bookie磁盘和网络状态
  - ledger_replication_lag:  # Ledger复制延迟
      threshold: ">1000ms"
      action: 检查网络延迟或增加Bookie节点
  - disk_usage:  # 磁盘使用率
      threshold: ">80%"
      action: 启用分层存储或扩容磁盘

namespace:
  - namespace_message_rate:  # Namespace消息速率
      threshold: ">quota"
      action: 调整Namespace配额或优化Producer
  - namespace_storage_usage:  # Namespace存储使用
      threshold: ">quota"
      action: 启用分层存储或调整保留策略
```

**运维痛点**：

1. **多组件监控**：需同时监控Broker、BookKeeper、ZooKeeper三个组件
2. **分层存储配置**：需配置对象存储（S3/HDFS）和卸载策略
3. **多租户管理**：需管理多个Tenant和Namespace的配额和权限

**运维优势**：

1. **存储计算分离**：Broker和BookKeeper可独立扩展
2. **分层存储**：自动卸载冷数据，存储成本降低60%
3. **原生多租户**：Namespace隔离，适合SaaS场景

## 3.2.3 SLO/SLA设定参考

| 指标 | Kafka | MQTT | NATS | Pulsar | 测量方法 | 运营目标 |
|------|-------|------|------|--------|----------|----------|
| **可用性** | 99.95% | 99.9% | 99.99% | 99.95% | ping/service monitor | NATS优势：自愈架构 |
| **延迟P99** | <100ms | <10ms | <1ms | <50ms | 客户端埋点 | NATS Core适合高频交易 |
| **吞吐量** | 100万TPS | 10万TPS | 200万TPS | 95万TPS | benchmark | Kafka适合大数据 |
| **数据持久性** | 99.999% | 99%* | 99.9%** | 99.999% | 故障注入测试 | Kafka和Pulsar副本机制最可靠 |
| **恢复时间RTO** | <5分钟 | <2分钟 | <10秒 | <10分钟 | 故障演练 | NATS无需人工干预 |
| **恢复点RPO** | 0秒 | 0-10秒 | 0-1秒 | <1分钟（地理复制） | 模拟Broker宕机 | 取决于刷盘策略 |
| **多租户隔离** | 无 | 无 | 无 | 原生支持 | 租户间性能影响 | Pulsar优势：原生多租户 |
| **分层存储** | 无 | 无 | 无 | 原生支持 | 存储成本 | Pulsar优势：存储成本降低60% |

*MQTT持久性依赖存储后端
**JetStream模式下

---

**参考来源**: 基于concept03.md内容整理
