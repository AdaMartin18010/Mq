# 3.3 故障场景与恢复策略

## 目录

- [3.3 故障场景与恢复策略](#33-故障场景与恢复策略)
  - [目录](#目录)
  - [3.3.1 Kafka典型故障场景](#331-kafka典型故障场景)
  - [3.3.2 MQTT典型故障场景](#332-mqtt典型故障场景)
  - [3.3.3 NATS典型故障场景](#333-nats典型故障场景)
  - [3.3.4 故障恢复对比矩阵](#334-故障恢复对比矩阵)
  - [3.3.5 故障预防策略](#335-故障预防策略)
    - [Kafka预防策略](#kafka预防策略)
    - [MQTT预防策略](#mqtt预防策略)
    - [NATS预防策略](#nats预防策略)

---

## 3.3.1 Kafka典型故障场景

| 故障类型 | 影响范围 | RTO | 恢复步骤 | 架构改进 |
|----------|----------|-----|----------|----------|
| **Broker宕机** | 部分分区不可用 | 30秒-2分钟 | 1. Controller选举新Leader<br>2. 客户端重试<br>3. 监控报警 | 增加副本因子至3，跨机架部署 |
| **Controller宕机** | 无法创建Topic/分区重分配 | 10-30秒 | 1. ZK触发新Controller选举<br>2. 恢复元数据管理 | 启用KRaft模式（Kafka 3.0+），消除ZK依赖 |
| **ZooKeeper脑裂** | 集群不可用 | 5-30分钟 | 1. 停止所有Broker<br>2. 修复ZK集群<br>3. 重启Broker | ZK与Broker物理隔离，监控ZK延迟 |
| **磁盘满** | Broker拒绝写入 | 即时 | 1. 清理旧日志(log.retention.ms)<br>2. 扩容磁盘 | 设置日志保留策略，监控磁盘使用率>70%报警 |
| **分区不均衡** | 热点Broker负载高 | 无自动恢复 | 1. 手动执行分区重分配<br>2. 运行preferred-replica-election | 启用自动均衡(auto.leader.rebalance.enable) |

**运维成本核算**：

- **故障频率**：月均1-2次Broker宕机，季度1次ZK相关问题
- **MTTR**：平均30分钟，需7×24小时专人值守
- **人力成本**：需1名Kafka专家+1名运维工程师

## 3.3.2 MQTT典型故障场景

| 故障类型 | 影响范围 | RTO | 恢复步骤 | 架构改进 |
|----------|----------|-----|----------|----------|
| **Broker宕机** | 所有连接断开 | 1-3分钟 | 1. 备用Broker接管<br>2. 设备重连<br>3. 会话恢复 | 共享存储+主从模式，设备端实现指数退避重连 |
| **设备重连风暴** | Broker CPU 100% | 5-10分钟 | 1. 限制连接速率<br>2. 扩容Broker<br>3. 清理僵尸会话 | 设备端随机化重连间隔，启用连接限流 |
| **主题订阅爆炸** | Broker内存溢出 | 即时 | 1. 重启Broker<br>2. 限制主题数量<br>3. 清理无效订阅 | 主题白名单策略，监控订阅数阈值 |
| **QoS2消息积压** | 消息延迟增高 | 无自动恢复 | 1. 降低QoS级别<br>2. 扩容Broker<br>3. 清理过期消息 | QoS2仅用于关键指令，普通数据用QoS0 |

**运维成本核算**：

- **故障频率**：设备重连风暴月均1次（网络抖动引起）
- **MTTR**：平均15分钟，需自动化重连策略
- **人力成本**：需1名MQTT协议专家

## 3.3.3 NATS典型故障场景

| 故障类型 | 影响范围 | RTO | 恢复步骤 | 架构改进 |
|----------|----------|-----|----------|----------|
| **单节点宕机** | 1/N连接断开 | **0秒** | 客户端自动重连到其他节点 | 无需操作，自愈 |
| **网络分区** | 小集群形成 | **秒级** | Gossip协议自动检测并合并 | 配置cluster.routes明确网络拓扑 |
| **慢消费者** | 消息投递延迟 | 无 | 监控报警，优化消费者 | 设置max_pending_msgs，超过则断开 |
| **内存耗尽** | 新连接被拒绝 | 即时 | 限制最大连接数 | 配置max_connections，监控内存使用 |
| **JetStream磁盘满** | 流写入失败 | 即时 | 清理旧消息或扩容磁盘 | 设置RetentionPolicy，监控磁盘 |

**运维成本核算**：

- **故障频率**：单节点宕机月均0.5次（硬件故障）
- **MTTR**：自动恢复，无需人工干预
- **人力成本**：0.5名通用运维工程师即可

## 3.3.4 故障恢复对比矩阵

| 故障类型 | Kafka恢复时间 | MQTT恢复时间 | NATS恢复时间 | 自动化程度 |
|----------|--------------|-------------|-------------|-----------|
| **节点宕机** | 30秒-2分钟 | 1-3分钟 | **0-5秒** | NATS最高 |
| **网络分区** | 5-30分钟 | 需人工干预 | **秒级自动** | NATS自动 |
| **资源耗尽** | 需人工扩容 | 需人工扩容 | **自动限流** | NATS自动保护 |
| **配置错误** | 需滚动重启 | 需主从切换 | **热加载** | NATS支持HUP信号 |

## 3.3.5 故障预防策略

### Kafka预防策略

1. **定期健康检查**：监控ISR状态、分区分布、磁盘使用率
2. **容量规划**：提前规划分区数和副本数，避免后期调整
3. **监控告警**：设置UnderReplicatedPartitions、Controller选举等关键指标
4. **演练预案**：定期进行故障演练，验证恢复流程

### MQTT预防策略

1. **连接限流**：防止设备重连风暴
2. **主题治理**：限制主题数量和层级深度
3. **会话管理**：定期清理过期会话，避免内存泄漏
4. **网络优化**：优化KeepAlive间隔，减少假在线

### NATS预防策略

1. **资源限制**：设置max_connections、max_memory等限制
2. **慢消费者保护**：自动断开慢消费者，保护系统整体
3. **监控告警**：监控Routes数量、内存使用、SlowConsumers
4. **自动化运维**：利用K8s HPA实现自动扩缩容

## 3.3.6 故障处理参考资源

### 故障处理理论

- **SRE实践**: [Site Reliability Engineering](https://sre.google/books/)
- **混沌工程**: [Chaos Engineering](https://principlesofchaos.org/)
- **故障分析**: [Postmortem Culture](https://sre.google/sre-book/postmortem-culture/)

### 故障处理参考

- **Kafka故障处理**: [Kafka Troubleshooting](https://kafka.apache.org/documentation/#troubleshooting)
- **MQTT故障处理**: [MQTT Troubleshooting](https://www.hivemq.com/blog/mqtt-essentials-part-8-mqtt-troubleshooting/)
- **NATS故障处理**: [NATS Troubleshooting](https://docs.nats.io/running-a-nats-service/nats_admin/troubleshooting)

---

**参考来源**:

- 基于concept03.md内容整理
- Google SRE实践和混沌工程理论
- Kafka、MQTT、NATS官方故障处理文档
- 生产环境故障案例和处理经验
