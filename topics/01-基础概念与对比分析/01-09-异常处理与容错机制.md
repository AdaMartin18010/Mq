# 1.9 异常处理与容错机制

## 目录

- [1.9 异常处理与容错机制](#19-异常处理与容错机制)
  - [目录](#目录)
  - [1.9.1 Kafka异常处理机制](#191-kafka异常处理机制)
    - [Producer异常处理](#producer异常处理)
    - [Consumer异常处理](#consumer异常处理)
    - [Broker异常处理](#broker异常处理)
  - [1.9.2 MQTT异常处理机制](#192-mqtt异常处理机制)
    - [连接异常处理](#连接异常处理)
    - [消息投递异常处理](#消息投递异常处理)
    - [QoS异常处理](#qos异常处理)
  - [1.9.3 NATS异常处理机制](#193-nats异常处理机制)
    - [连接异常处理](#连接异常处理-1)
    - [消息投递异常处理](#消息投递异常处理-1)
    - [JetStream异常处理](#jetstream异常处理)
  - [1.9.4 容错机制对比矩阵](#194-容错机制对比矩阵)
  - [1.9.5 异常处理最佳实践](#195-异常处理最佳实践)
    - [通用最佳实践](#通用最佳实践)
    - [Kafka最佳实践](#kafka最佳实践)
    - [MQTT最佳实践](#mqtt最佳实践)
    - [NATS最佳实践](#nats最佳实践)
  - [1.9.6 异常处理参考资源](#196-异常处理参考资源)
    - [异常处理理论](#异常处理理论)
    - [技术参考](#技术参考)

---

## 1.9.1 Kafka异常处理机制

### Producer异常处理

**异常类型**：

| 异常类型 | 原因 | 处理策略 | 代码示例 |
|---------|------|----------|----------|
| **NetworkException** | 网络连接失败 | 自动重试（retries配置） | `retries=2147483647` |
| **TimeoutException** | 请求超时 | 增加超时时间或重试 | `request.timeout.ms=30000` |
| **NotEnoughReplicasException** | ISR副本不足 | 等待副本恢复或降低acks | `acks=1`（降级） |
| **SerializationException** | 序列化失败 | 检查数据格式 | 使用Schema Registry |
| **RecordTooLargeException** | 消息过大 | 分割消息或增加max.request.size | `max.request.size=10485760` |

**代码示例**：

```java
// Kafka Producer异常处理最佳实践
Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("retries", 2147483647);  // 无限重试
props.put("max.in.flight.requests.per.connection", 1);  // 单请求模式
props.put("enable.idempotence", true);  // 幂等性保证

KafkaProducer<String, String> producer = new KafkaProducer<>(props);

try {
    ProducerRecord<String, String> record = new ProducerRecord<>("topic", "key", "value");

    // 同步发送，捕获异常
    RecordMetadata metadata = producer.send(record).get();

} catch (InterruptedException e) {
    // 线程中断异常
    Thread.currentThread().interrupt();
    log.error("Producer interrupted", e);

} catch (ExecutionException e) {
    // 执行异常，检查根本原因
    Throwable cause = e.getCause();

    if (cause instanceof RetriableException) {
        // 可重试异常，Producer会自动重试
        log.warn("Retriable exception, will retry", cause);
    } else if (cause instanceof NonRetriableException) {
        // 不可重试异常，需要人工处理
        log.error("Non-retriable exception", cause);
        // 记录到死信队列或告警
    }

} catch (SerializationException e) {
    // 序列化异常，数据格式错误
    log.error("Serialization failed", e);
    // 记录到死信队列

} catch (RecordTooLargeException e) {
    // 消息过大
    log.error("Record too large: {} bytes", e.recordSize());
    // 分割消息或丢弃
}
```

**参考**: [Kafka Producer Error Handling](https://kafka.apache.org/documentation/#producerconfigs)

### Consumer异常处理

**异常类型**：

| 异常类型 | 原因 | 处理策略 | 代码示例 |
|---------|------|----------|----------|
| **CommitFailedException** | 提交offset失败 | 检查Consumer Group状态 | 增加`max.poll.interval.ms` |
| **WakeupException** | Consumer被唤醒 | 正常关闭流程 | 调用`consumer.wakeup()` |
| **DeserializationException** | 反序列化失败 | 跳过消息或记录 | 使用`ErrorHandlingDeserializer` |
| **OffsetOutOfRangeException** | Offset超出范围 | 重置offset | `auto.offset.reset=earliest` |
| **RebalanceException** | Rebalance失败 | 检查Consumer配置 | 减少`max.poll.records` |

**代码示例**：

```java
// Kafka Consumer异常处理最佳实践
Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("group.id", "my-group");
props.put("enable.auto.commit", false);  // 手动提交
props.put("auto.offset.reset", "earliest");
props.put("max.poll.records", 500);
props.put("max.poll.interval.ms", 300000);  // 5分钟超时

KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
consumer.subscribe(Arrays.asList("topic"));

try {
    while (true) {
        ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));

        for (ConsumerRecord<String, String> record : records) {
            try {
                // 处理消息
                processMessage(record);

            } catch (DeserializationException e) {
                // 反序列化异常，跳过消息
                log.error("Deserialization failed for record: {}", record.offset(), e);
                // 记录到死信队列
                sendToDeadLetterQueue(record);

            } catch (BusinessException e) {
                // 业务异常，记录但继续处理
                log.error("Business logic error", e);
                // 记录到错误日志或告警
            }
        }

        try {
            // 手动提交offset
            consumer.commitSync();
        } catch (CommitFailedException e) {
            // 提交失败，可能发生Rebalance
            log.warn("Commit failed, may be rebalancing", e);
        }
    }

} catch (WakeupException e) {
    // 正常关闭
    log.info("Consumer wakeup, closing");

} catch (Exception e) {
    // 其他异常
    log.error("Unexpected error", e);

} finally {
    consumer.close();
}
```

**参考**: [Kafka Consumer Error Handling](https://kafka.apache.org/documentation/#consumerconfigs)

### Broker异常处理

**异常场景**：

1. **磁盘满异常**
   - **检测**: 监控`kafka.server:type=KafkaServer,name=BrokerState`
   - **处理**: 清理旧日志或扩容磁盘
   - **预防**: 设置`log.retention.hours`和磁盘监控告警

2. **内存溢出异常**
   - **检测**: 监控JVM堆内存使用率
   - **处理**: 增加堆内存或减少并发连接数
   - **预防**: 设置`num.network.threads`和`num.io.threads`

3. **网络分区异常**
   - **检测**: 监控ISR收缩和副本延迟
   - **处理**: 修复网络或等待网络恢复
   - **预防**: 跨机架部署和网络监控

**参考**: [Kafka Broker Troubleshooting](https://kafka.apache.org/documentation/#troubleshooting)

## 1.9.2 MQTT异常处理机制

### 连接异常处理

**异常类型**：

| 异常类型 | 原因 | 处理策略 | 代码示例 |
|---------|------|----------|----------|
| **ConnectionException** | 连接失败 | 指数退避重连 | 实现重连策略 |
| **TimeoutException** | 连接超时 | 增加超时时间 | `keepalive=60` |
| **AuthenticationException** | 认证失败 | 检查凭证 | 使用TLS和证书 |
| **NetworkException** | 网络中断 | 自动重连 | 监听连接状态 |

**代码示例**：

```python
# MQTT客户端异常处理和重连策略
import paho.mqtt.client as mqtt
import time
import logging

class RobustMQTTClient:
    def __init__(self, broker, port=1883):
        self.broker = broker
        self.port = port
        self.client = mqtt.Client()
        self.client.on_connect = self.on_connect
        self.client.on_disconnect = self.on_disconnect
        self.client.on_message = self.on_message
        self.retry_count = 0
        self.max_retries = 10

    def on_connect(self, client, userdata, flags, rc):
        """连接回调"""
        if rc == 0:
            logging.info("Connected successfully")
            self.retry_count = 0  # 重置重试计数
            client.subscribe("topic/#")
        else:
            logging.error(f"Connection failed with code {rc}")
            # 根据返回码处理
            if rc == 1:  # 协议版本不正确
                raise ValueError("Unsupported protocol version")
            elif rc == 2:  # 客户端ID无效
                raise ValueError("Invalid client identifier")
            elif rc == 3:  # Broker不可用
                self.reconnect_with_backoff()
            elif rc == 4:  # 用户名或密码错误
                raise ValueError("Authentication failed")
            elif rc == 5:  # 未授权
                raise PermissionError("Not authorized")

    def on_disconnect(self, client, userdata, rc):
        """断开连接回调"""
        if rc != 0:
            logging.warning(f"Unexpected disconnection (rc={rc})")
            self.reconnect_with_backoff()
        else:
            logging.info("Disconnected normally")

    def reconnect_with_backoff(self):
        """指数退避重连"""
        while self.retry_count < self.max_retries:
            wait_time = min(2 ** self.retry_count, 60)  # 最多等待60秒
            logging.info(f"Reconnecting in {wait_time} seconds (attempt {self.retry_count + 1})")
            time.sleep(wait_time)

            try:
                self.client.reconnect()
                return True
            except Exception as e:
                logging.error(f"Reconnection failed: {e}")
                self.retry_count += 1

        logging.error("Max retries reached, giving up")
        return False

    def on_message(self, client, userdata, msg):
        """消息回调"""
        try:
            # 处理消息
            self.process_message(msg.topic, msg.payload)
        except Exception as e:
            logging.error(f"Error processing message: {e}")
            # 记录错误但不中断连接

    def connect(self):
        """连接Broker"""
        try:
            self.client.connect(self.broker, self.port, keepalive=60)
            self.client.loop_start()
        except Exception as e:
            logging.error(f"Connection error: {e}")
            self.reconnect_with_backoff()
```

**参考**: [MQTT Connection Error Codes](https://docs.oasis-open.org/mqtt/mqtt/v5.0/mqtt-v5.0.html#_Toc3901031)

### 消息投递异常处理

**QoS异常处理**：

```python
# QoS 1消息投递异常处理
def publish_with_retry(client, topic, payload, qos=1, max_retries=3):
    """带重试的消息发布"""
    for attempt in range(max_retries):
        try:
            result = client.publish(topic, payload, qos=qos)

            if result.rc == mqtt.MQTT_ERR_SUCCESS:
                # 等待PUBACK确认
                if qos == 1:
                    result.wait_for_publish()
                return True
            else:
                raise Exception(f"Publish failed with code {result.rc}")

        except Exception as e:
            logging.warning(f"Publish attempt {attempt + 1} failed: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)  # 指数退避
            else:
                logging.error("Max retries reached, message lost")
                return False

    return False
```

### QoS异常处理

**QoS 2四步握手异常处理**：

```python
# QoS 2异常处理
def handle_qos2_exception(client, msg_id):
    """处理QoS 2异常情况"""
    # 如果PUBREL丢失，需要重发
    # MQTT客户端库通常会自动处理
    pass

# 使用持久会话恢复QoS 2消息
client = mqtt.Client(client_id="my-client", clean_session=False)
# Clean Session=False时，Broker会保存QoS 1和QoS 2消息
```

**参考**: [MQTT QoS Error Handling](https://docs.oasis-open.org/mqtt/mqtt/v5.0/mqtt-v5.0.html#_Toc3901233)

## 1.9.3 NATS异常处理机制

### 连接异常处理

**异常类型**：

| 异常类型 | 原因 | 处理策略 | 代码示例 |
|---------|------|----------|----------|
| **ErrNoServers** | 无可用服务器 | 自动重连到其他服务器 | `MaxReconnects(-1)` |
| **ErrConnectionClosed** | 连接关闭 | 自动重连 | `ReconnectWait(1s)` |
| **ErrTimeout** | 请求超时 | 增加超时时间或重试 | `Timeout(10s)` |
| **ErrSlowConsumer** | 慢消费者 | 断开连接或优化处理 | `MaxPendingMsgs(1000)` |

**代码示例**：

```go
// NATS客户端异常处理和重连策略
package main

import (
    "fmt"
    "log"
    "time"
    "github.com/nats-io/nats.go"
)

func main() {
    // 配置重连选项
    opts := []nats.Option{
        nats.MaxReconnects(-1),  // 无限重连
        nats.ReconnectWait(1 * time.Second),
        nats.ReconnectJitter(500*time.Millisecond, 2*time.Second),
        nats.Timeout(10 * time.Second),
        nats.DisconnectErrHandler(func(nc *nats.Conn, err error) {
            if err != nil {
                log.Printf("Disconnected: %v", err)
            }
        }),
        nats.ReconnectHandler(func(nc *nats.Conn) {
            log.Printf("Reconnected to %v", nc.ConnectedUrl())
        }),
        nats.ClosedHandler(func(nc *nats.Conn) {
            log.Printf("Connection closed")
        }),
        nats.ErrorHandler(func(nc *nats.Conn, sub *nats.Subscription, err error) {
            log.Printf("Error: %v", err)
            if err == nats.ErrSlowConsumer {
                // 慢消费者，断开连接
                log.Printf("Slow consumer detected, disconnecting")
                nc.Close()
            }
        }),
    }

    // 连接NATS服务器
    nc, err := nats.Connect("nats://localhost:4222", opts...)
    if err != nil {
        log.Fatal(err)
    }
    defer nc.Close()

    // 订阅消息
    sub, err := nc.Subscribe("subject", func(msg *nats.Msg) {
        defer func() {
            if r := recover(); r != nil {
                // 捕获panic，防止程序崩溃
                log.Printf("Panic in message handler: %v", r)
            }
        }()

        // 处理消息
        if err := processMessage(msg.Data); err != nil {
            log.Printf("Error processing message: %v", err)
            // 不ACK消息，等待重试（JetStream模式）
        }
    })

    if err != nil {
        log.Fatal(err)
    }

    // 设置最大待处理消息数
    if err := sub.SetPendingLimits(1000, 10*1024*1024); err != nil {
        log.Printf("Error setting pending limits: %v", err)
    }

    // 保持连接
    select {}
}

func processMessage(data []byte) error {
    // 处理消息逻辑
    return nil
}
```

**参考**: [NATS Error Handling](https://docs.nats.io/using-nats/developer/connecting/errors)

### 消息投递异常处理

**JetStream异常处理**：

```go
// JetStream异常处理
js, err := nc.JetStream()

// 创建Consumer，配置错误处理
sub, err := js.Subscribe("subject", func(msg *nats.Msg) {
    defer func() {
        if r := recover(); r != nil {
            log.Printf("Panic: %v", r)
            // 不ACK，等待重试
            return
        }
    }()

    if err := processMessage(msg.Data); err != nil {
        // 处理失败，不ACK，等待重试
        log.Printf("Processing failed: %v", err)
        return
    }

    // 处理成功，ACK消息
    msg.Ack()
}, nats.MaxDeliver(5))  // 最多重试5次

// 配置死信队列
sub, err := js.Subscribe("subject", handler,
    nats.MaxDeliver(5),
    nats.AckWait(30*time.Second),
    nats.DeliverSubject("dlq.subject"),  // 死信队列
)
```

### JetStream异常处理

**流异常处理**：

```go
// Stream异常处理
js.AddStream(&nats.StreamConfig{
    Name:     "ORDERS",
    Subjects: []string{"orders.>"},
    Retention: nats.LimitsPolicy,
    MaxAge:    24 * time.Hour,
    Storage:   nats.FileStorage,
    Replicas:  3,
    Discard:   nats.DiscardOld,  // 磁盘满时丢弃旧消息
    MaxBytes:  100 * 1024 * 1024 * 1024,  // 100GB限制
})
```

## 1.9.4 容错机制对比矩阵

| 容错维度 | Kafka | MQTT | NATS Core | NATS JetStream |
|---------|-------|------|-----------|----------------|
| **连接容错** | 自动重连（客户端） | 自动重连+会话恢复 | 自动重连（多服务器） | 自动重连+Raft恢复 |
| **消息容错** | 副本机制+ACK | QoS分级保证 | 无（最多一次） | Raft共识+ACK |
| **网络分区容错** | CP系统，等待恢复 | 主从切换 | AP系统，继续服务 | CP系统，等待恢复 |
| **慢消费者容错** | 无保护机制 | 无保护机制 | 自动断开保护 | 自动断开+死信队列 |
| **磁盘满容错** | 拒绝写入 | 丢弃消息 | 无（内存） | 丢弃旧消息或拒绝写入 |
| **异常恢复时间** | 30秒-2分钟 | 1-3分钟 | 0-5秒 | 1-10秒 |
| **数据丢失风险** | 低（副本机制） | 中（QoS分级） | 高（无持久化） | 低（Raft共识） |

## 1.9.5 异常处理最佳实践

### 通用最佳实践

1. **重试策略**
   - 指数退避：`wait_time = min(2^retry_count, max_wait)`
   - 最大重试次数：避免无限重试
   - 可重试异常识别：区分可重试和不可重试异常

2. **死信队列**
   - 记录所有处理失败的消息
   - 定期分析和处理死信消息
   - 告警机制：死信消息过多时告警

3. **监控告警**
   - 异常频率监控
   - 异常类型统计
   - 异常恢复时间监控

4. **日志记录**
   - 记录所有异常信息
   - 包含上下文信息（消息ID、时间戳等）
   - 结构化日志便于分析

### Kafka最佳实践

```java
// Kafka异常处理最佳实践
public class KafkaErrorHandler {
    private DeadLetterQueueProducer dlqProducer;

    public void handleException(ConsumerRecord<String, String> record, Exception e) {
        if (e instanceof DeserializationException) {
            // 反序列化异常，发送到死信队列
            dlqProducer.send(record, "DESERIALIZATION_ERROR", e);
        } else if (e instanceof BusinessException) {
            // 业务异常，记录日志
            log.error("Business error for record: {}", record.offset(), e);
        } else {
            // 其他异常，重试或发送到死信队列
            if (isRetriable(e)) {
                throw new RetryableException(e);
            } else {
                dlqProducer.send(record, "UNKNOWN_ERROR", e);
            }
        }
    }
}
```

### MQTT最佳实践

```python
# MQTT异常处理最佳实践
class MQTTErrorHandler:
    def __init__(self):
        self.dlq_client = mqtt.Client()
        self.error_count = {}

    def handle_publish_error(self, topic, payload, error):
        """处理发布错误"""
        error_type = type(error).__name__
        self.error_count[error_type] = self.error_count.get(error_type, 0) + 1

        if self.error_count[error_type] > 10:
            # 错误过多，告警
            send_alert(f"Too many {error_type} errors")

        # 记录到死信队列
        self.dlq_client.publish(f"dlq/{topic}", payload, qos=1)
```

### NATS最佳实践

```go
// NATS异常处理最佳实践
func handleNATSError(nc *nats.Conn, sub *nats.Subscription, err error) {
    switch err {
    case nats.ErrSlowConsumer:
        // 慢消费者，断开连接保护系统
        log.Printf("Slow consumer detected, disconnecting")
        nc.Close()
    case nats.ErrTimeout:
        // 超时，记录但不中断
        log.Printf("Request timeout")
    case nats.ErrNoResponders:
        // 无响应者，记录
        log.Printf("No responders for request")
    default:
        // 其他错误
        log.Printf("Unexpected error: %v", err)
    }
}
```

---

## 1.9.6 异常处理参考资源

### 异常处理理论

- **容错系统设计**: [Fault Tolerance](https://en.wikipedia.org/wiki/Fault_tolerance)
- **错误处理模式**: [Error Handling Patterns](https://martinfowler.com/articles/replaceThrowWithNotification.html)
- **重试模式**: [Retry Pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/retry)

### 技术参考

- **Kafka异常处理**: [Kafka Error Handling](https://kafka.apache.org/documentation/#design_guarantees)
- **MQTT异常处理**: [MQTT Error Handling](https://docs.oasis-open.org/mqtt/mqtt/v5.0/mqtt-v5.0.html#_Toc3901031)
- **NATS异常处理**: [NATS Error Handling](https://docs.nats.io/using-nats/developer/connecting/errors)

---

**参考来源**:

- 基于concept01.md和concept03.md内容整理
- Kafka、MQTT、NATS官方文档中的异常处理说明
- 容错系统设计理论和最佳实践
- 生产环境异常处理经验

**最后更新**: 2025-12-31
