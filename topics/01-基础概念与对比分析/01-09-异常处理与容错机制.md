# 1.9 异常处理与容错机制

## 目录

- [1.9 异常处理与容错机制](#19-异常处理与容错机制)
  - [目录](#目录)
  - [1.9.1 Kafka异常处理机制](#191-kafka异常处理机制)
    - [Producer异常处理](#producer异常处理)
    - [Consumer异常处理](#consumer异常处理)
    - [Broker异常处理](#broker异常处理)
  - [1.9.2 MQTT异常处理机制](#192-mqtt异常处理机制)
    - [连接异常处理](#连接异常处理)
    - [消息投递异常处理](#消息投递异常处理)
    - [QoS异常处理](#qos异常处理)
  - [1.9.3 NATS异常处理机制](#193-nats异常处理机制)
    - [连接异常处理](#连接异常处理-1)
    - [消息投递异常处理](#消息投递异常处理-1)
    - [JetStream异常处理](#jetstream异常处理)
  - [1.9.4 Pulsar异常处理机制](#194-pulsar异常处理机制)
    - [Producer异常处理](#producer异常处理-1)
    - [Consumer异常处理](#consumer异常处理-1)
    - [连接异常处理](#连接异常处理-2)
    - [Broker异常处理](#broker异常处理-1)
    - [BookKeeper异常处理](#bookkeeper异常处理)
  - [1.9.5 容错机制对比矩阵](#195-容错机制对比矩阵)
  - [1.9.6 异常处理最佳实践](#196-异常处理最佳实践)
    - [通用最佳实践](#通用最佳实践)
    - [Kafka最佳实践](#kafka最佳实践)
    - [MQTT最佳实践](#mqtt最佳实践)
    - [NATS最佳实践](#nats最佳实践)
    - [Pulsar最佳实践](#pulsar最佳实践)
  - [1.9.6 异常处理参考资源](#196-异常处理参考资源)
    - [异常处理理论](#异常处理理论)
    - [技术参考](#技术参考)

---

## 1.9.1 Kafka异常处理机制

### Producer异常处理

**异常类型**：

| 异常类型 | 原因 | 处理策略 | 代码示例 |
|---------|------|----------|----------|
| **NetworkException** | 网络连接失败 | 自动重试（retries配置） | `retries=2147483647` |
| **TimeoutException** | 请求超时 | 增加超时时间或重试 | `request.timeout.ms=30000` |
| **NotEnoughReplicasException** | ISR副本不足 | 等待副本恢复或降低acks | `acks=1`（降级） |
| **SerializationException** | 序列化失败 | 检查数据格式 | 使用Schema Registry |
| **RecordTooLargeException** | 消息过大 | 分割消息或增加max.request.size | `max.request.size=10485760` |

**代码示例**：

```java
// Kafka Producer异常处理最佳实践
Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("retries", 2147483647);  // 无限重试
props.put("max.in.flight.requests.per.connection", 1);  // 单请求模式
props.put("enable.idempotence", true);  // 幂等性保证

KafkaProducer<String, String> producer = new KafkaProducer<>(props);

try {
    ProducerRecord<String, String> record = new ProducerRecord<>("topic", "key", "value");

    // 同步发送，捕获异常
    RecordMetadata metadata = producer.send(record).get();

} catch (InterruptedException e) {
    // 线程中断异常
    Thread.currentThread().interrupt();
    log.error("Producer interrupted", e);

} catch (ExecutionException e) {
    // 执行异常，检查根本原因
    Throwable cause = e.getCause();

    if (cause instanceof RetriableException) {
        // 可重试异常，Producer会自动重试
        log.warn("Retriable exception, will retry", cause);
    } else if (cause instanceof NonRetriableException) {
        // 不可重试异常，需要人工处理
        log.error("Non-retriable exception", cause);
        // 记录到死信队列或告警
    }

} catch (SerializationException e) {
    // 序列化异常，数据格式错误
    log.error("Serialization failed", e);
    // 记录到死信队列

} catch (RecordTooLargeException e) {
    // 消息过大
    log.error("Record too large: {} bytes", e.recordSize());
    // 分割消息或丢弃
}
```

**参考**: [Kafka Producer Error Handling](https://kafka.apache.org/documentation/#producerconfigs)

### Consumer异常处理

**异常类型**：

| 异常类型 | 原因 | 处理策略 | 代码示例 |
|---------|------|----------|----------|
| **CommitFailedException** | 提交offset失败 | 检查Consumer Group状态 | 增加`max.poll.interval.ms` |
| **WakeupException** | Consumer被唤醒 | 正常关闭流程 | 调用`consumer.wakeup()` |
| **DeserializationException** | 反序列化失败 | 跳过消息或记录 | 使用`ErrorHandlingDeserializer` |
| **OffsetOutOfRangeException** | Offset超出范围 | 重置offset | `auto.offset.reset=earliest` |
| **RebalanceException** | Rebalance失败 | 检查Consumer配置 | 减少`max.poll.records` |

**代码示例**：

```java
// Kafka Consumer异常处理最佳实践
Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("group.id", "my-group");
props.put("enable.auto.commit", false);  // 手动提交
props.put("auto.offset.reset", "earliest");
props.put("max.poll.records", 500);
props.put("max.poll.interval.ms", 300000);  // 5分钟超时

KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
consumer.subscribe(Arrays.asList("topic"));

try {
    while (true) {
        ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));

        for (ConsumerRecord<String, String> record : records) {
            try {
                // 处理消息
                processMessage(record);

            } catch (DeserializationException e) {
                // 反序列化异常，跳过消息
                log.error("Deserialization failed for record: {}", record.offset(), e);
                // 记录到死信队列
                sendToDeadLetterQueue(record);

            } catch (BusinessException e) {
                // 业务异常，记录但继续处理
                log.error("Business logic error", e);
                // 记录到错误日志或告警
            }
        }

        try {
            // 手动提交offset
            consumer.commitSync();
        } catch (CommitFailedException e) {
            // 提交失败，可能发生Rebalance
            log.warn("Commit failed, may be rebalancing", e);
        }
    }

} catch (WakeupException e) {
    // 正常关闭
    log.info("Consumer wakeup, closing");

} catch (Exception e) {
    // 其他异常
    log.error("Unexpected error", e);

} finally {
    consumer.close();
}
```

**参考**: [Kafka Consumer Error Handling](https://kafka.apache.org/documentation/#consumerconfigs)

### Broker异常处理

**异常场景**：

1. **磁盘满异常**
   - **检测**: 监控`kafka.server:type=KafkaServer,name=BrokerState`
   - **处理**: 清理旧日志或扩容磁盘
   - **预防**: 设置`log.retention.hours`和磁盘监控告警

2. **内存溢出异常**
   - **检测**: 监控JVM堆内存使用率
   - **处理**: 增加堆内存或减少并发连接数
   - **预防**: 设置`num.network.threads`和`num.io.threads`

3. **网络分区异常**
   - **检测**: 监控ISR收缩和副本延迟
   - **处理**: 修复网络或等待网络恢复
   - **预防**: 跨机架部署和网络监控

**参考**: [Kafka Broker Troubleshooting](https://kafka.apache.org/documentation/#troubleshooting)

## 1.9.2 MQTT异常处理机制

### 连接异常处理

**异常类型**：

| 异常类型 | 原因 | 处理策略 | 代码示例 |
|---------|------|----------|----------|
| **ConnectionException** | 连接失败 | 指数退避重连 | 实现重连策略 |
| **TimeoutException** | 连接超时 | 增加超时时间 | `keepalive=60` |
| **AuthenticationException** | 认证失败 | 检查凭证 | 使用TLS和证书 |
| **NetworkException** | 网络中断 | 自动重连 | 监听连接状态 |

**代码示例**：

```python
# MQTT客户端异常处理和重连策略
import paho.mqtt.client as mqtt
import time
import logging

class RobustMQTTClient:
    def __init__(self, broker, port=1883):
        self.broker = broker
        self.port = port
        self.client = mqtt.Client()
        self.client.on_connect = self.on_connect
        self.client.on_disconnect = self.on_disconnect
        self.client.on_message = self.on_message
        self.retry_count = 0
        self.max_retries = 10

    def on_connect(self, client, userdata, flags, rc):
        """连接回调"""
        if rc == 0:
            logging.info("Connected successfully")
            self.retry_count = 0  # 重置重试计数
            client.subscribe("topic/#")
        else:
            logging.error(f"Connection failed with code {rc}")
            # 根据返回码处理
            if rc == 1:  # 协议版本不正确
                raise ValueError("Unsupported protocol version")
            elif rc == 2:  # 客户端ID无效
                raise ValueError("Invalid client identifier")
            elif rc == 3:  # Broker不可用
                self.reconnect_with_backoff()
            elif rc == 4:  # 用户名或密码错误
                raise ValueError("Authentication failed")
            elif rc == 5:  # 未授权
                raise PermissionError("Not authorized")

    def on_disconnect(self, client, userdata, rc):
        """断开连接回调"""
        if rc != 0:
            logging.warning(f"Unexpected disconnection (rc={rc})")
            self.reconnect_with_backoff()
        else:
            logging.info("Disconnected normally")

    def reconnect_with_backoff(self):
        """指数退避重连"""
        while self.retry_count < self.max_retries:
            wait_time = min(2 ** self.retry_count, 60)  # 最多等待60秒
            logging.info(f"Reconnecting in {wait_time} seconds (attempt {self.retry_count + 1})")
            time.sleep(wait_time)

            try:
                self.client.reconnect()
                return True
            except Exception as e:
                logging.error(f"Reconnection failed: {e}")
                self.retry_count += 1

        logging.error("Max retries reached, giving up")
        return False

    def on_message(self, client, userdata, msg):
        """消息回调"""
        try:
            # 处理消息
            self.process_message(msg.topic, msg.payload)
        except Exception as e:
            logging.error(f"Error processing message: {e}")
            # 记录错误但不中断连接

    def connect(self):
        """连接Broker"""
        try:
            self.client.connect(self.broker, self.port, keepalive=60)
            self.client.loop_start()
        except Exception as e:
            logging.error(f"Connection error: {e}")
            self.reconnect_with_backoff()
```

**参考**: [MQTT Connection Error Codes](https://docs.oasis-open.org/mqtt/mqtt/v5.0/mqtt-v5.0.html#_Toc3901031)

### 消息投递异常处理

**QoS异常处理**：

```python
# QoS 1消息投递异常处理
def publish_with_retry(client, topic, payload, qos=1, max_retries=3):
    """带重试的消息发布"""
    for attempt in range(max_retries):
        try:
            result = client.publish(topic, payload, qos=qos)

            if result.rc == mqtt.MQTT_ERR_SUCCESS:
                # 等待PUBACK确认
                if qos == 1:
                    result.wait_for_publish()
                return True
            else:
                raise Exception(f"Publish failed with code {result.rc}")

        except Exception as e:
            logging.warning(f"Publish attempt {attempt + 1} failed: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)  # 指数退避
            else:
                logging.error("Max retries reached, message lost")
                return False

    return False
```

### QoS异常处理

**QoS 2四步握手异常处理**：

```python
# QoS 2异常处理
def handle_qos2_exception(client, msg_id):
    """处理QoS 2异常情况"""
    # 如果PUBREL丢失，需要重发
    # MQTT客户端库通常会自动处理
    pass

# 使用持久会话恢复QoS 2消息
client = mqtt.Client(client_id="my-client", clean_session=False)
# Clean Session=False时，Broker会保存QoS 1和QoS 2消息
```

**参考**: [MQTT QoS Error Handling](https://docs.oasis-open.org/mqtt/mqtt/v5.0/mqtt-v5.0.html#_Toc3901233)

## 1.9.3 NATS异常处理机制

### 连接异常处理

**异常类型**：

| 异常类型 | 原因 | 处理策略 | 代码示例 |
|---------|------|----------|----------|
| **ErrNoServers** | 无可用服务器 | 自动重连到其他服务器 | `MaxReconnects(-1)` |
| **ErrConnectionClosed** | 连接关闭 | 自动重连 | `ReconnectWait(1s)` |
| **ErrTimeout** | 请求超时 | 增加超时时间或重试 | `Timeout(10s)` |
| **ErrSlowConsumer** | 慢消费者 | 断开连接或优化处理 | `MaxPendingMsgs(1000)` |

**代码示例**：

```go
// NATS客户端异常处理和重连策略
package main

import (
    "fmt"
    "log"
    "time"
    "github.com/nats-io/nats.go"
)

func main() {
    // 配置重连选项
    opts := []nats.Option{
        nats.MaxReconnects(-1),  // 无限重连
        nats.ReconnectWait(1 * time.Second),
        nats.ReconnectJitter(500*time.Millisecond, 2*time.Second),
        nats.Timeout(10 * time.Second),
        nats.DisconnectErrHandler(func(nc *nats.Conn, err error) {
            if err != nil {
                log.Printf("Disconnected: %v", err)
            }
        }),
        nats.ReconnectHandler(func(nc *nats.Conn) {
            log.Printf("Reconnected to %v", nc.ConnectedUrl())
        }),
        nats.ClosedHandler(func(nc *nats.Conn) {
            log.Printf("Connection closed")
        }),
        nats.ErrorHandler(func(nc *nats.Conn, sub *nats.Subscription, err error) {
            log.Printf("Error: %v", err)
            if err == nats.ErrSlowConsumer {
                // 慢消费者，断开连接
                log.Printf("Slow consumer detected, disconnecting")
                nc.Close()
            }
        }),
    }

    // 连接NATS服务器
    nc, err := nats.Connect("nats://localhost:4222", opts...)
    if err != nil {
        log.Fatal(err)
    }
    defer nc.Close()

    // 订阅消息
    sub, err := nc.Subscribe("subject", func(msg *nats.Msg) {
        defer func() {
            if r := recover(); r != nil {
                // 捕获panic，防止程序崩溃
                log.Printf("Panic in message handler: %v", r)
            }
        }()

        // 处理消息
        if err := processMessage(msg.Data); err != nil {
            log.Printf("Error processing message: %v", err)
            // 不ACK消息，等待重试（JetStream模式）
        }
    })

    if err != nil {
        log.Fatal(err)
    }

    // 设置最大待处理消息数
    if err := sub.SetPendingLimits(1000, 10*1024*1024); err != nil {
        log.Printf("Error setting pending limits: %v", err)
    }

    // 保持连接
    select {}
}

func processMessage(data []byte) error {
    // 处理消息逻辑
    return nil
}
```

**参考**: [NATS Error Handling](https://docs.nats.io/using-nats/developer/connecting/errors)

### 消息投递异常处理

**JetStream异常处理**：

```go
// JetStream异常处理
js, err := nc.JetStream()

// 创建Consumer，配置错误处理
sub, err := js.Subscribe("subject", func(msg *nats.Msg) {
    defer func() {
        if r := recover(); r != nil {
            log.Printf("Panic: %v", r)
            // 不ACK，等待重试
            return
        }
    }()

    if err := processMessage(msg.Data); err != nil {
        // 处理失败，不ACK，等待重试
        log.Printf("Processing failed: %v", err)
        return
    }

    // 处理成功，ACK消息
    msg.Ack()
}, nats.MaxDeliver(5))  // 最多重试5次

// 配置死信队列
sub, err := js.Subscribe("subject", handler,
    nats.MaxDeliver(5),
    nats.AckWait(30*time.Second),
    nats.DeliverSubject("dlq.subject"),  // 死信队列
)
```

### JetStream异常处理

**流异常处理**：

```go
// Stream异常处理
js.AddStream(&nats.StreamConfig{
    Name:     "ORDERS",
    Subjects: []string{"orders.>"},
    Retention: nats.LimitsPolicy,
    MaxAge:    24 * time.Hour,
    Storage:   nats.FileStorage,
    Replicas:  3,
    Discard:   nats.DiscardOld,  // 磁盘满时丢弃旧消息
    MaxBytes:  100 * 1024 * 1024 * 1024,  // 100GB限制
})
```

## 1.9.4 Pulsar异常处理机制

### Producer异常处理

**异常类型**（基于concept06.md和Pulsar官方文档）：

| 异常类型 | 原因 | 处理策略 | 代码示例 |
|---------|------|----------|----------|
| **PulsarClientException** | 客户端连接失败 | 自动重连（ConnectionTimeout配置） | `connectionTimeoutMs=10000` |
| **TimeoutException** | 发送超时 | 增加超时时间或重试 | `sendTimeoutMs=30000` |
| **ProducerQueueIsFullError** | Producer队列满 | 阻塞或丢弃（blockIfQueueFull配置） | `blockIfQueueFull=true` |
| **SchemaSerializationException** | Schema序列化失败 | 检查Schema兼容性 | 使用Schema.AVRO/JSON |
| **MessageTooLargeException** | 消息过大 | 分割消息或增加maxMessageSize | `maxPendingMessages=1000` |
| **NotAuthorizedException** | 权限不足 | 检查认证和授权 | 使用TLS/OAuth2 |

**Java代码示例**（基于concept06.md）：

```java
// Pulsar Producer异常处理最佳实践
import org.apache.pulsar.client.api.*;

public class RobustPulsarProducer {
    private PulsarClient client;
    private Producer<String> producer;
    private static final int MAX_RETRIES = 3;
    private static final long INITIAL_DELAY_MS = 1000;

    public void initialize() throws PulsarClientException {
        client = PulsarClient.builder()
            .serviceUrl("pulsar://localhost:6650")
            .connectionTimeout(10, TimeUnit.SECONDS)
            .operationTimeout(30, TimeUnit.SECONDS)
            .build();

        producer = client.newProducer(Schema.STRING)
            .topic("my-topic")
            .sendTimeout(30, TimeUnit.SECONDS)
            .maxPendingMessages(1000)
            .blockIfQueueFull(true)
            .enableBatching(true)
            .batchingMaxPublishDelay(10, TimeUnit.MILLISECONDS)
            .create();
    }

    public CompletableFuture<MessageId> sendWithRetry(String message) {
        return sendWithRetry(message, 0);
    }

    private CompletableFuture<MessageId> sendWithRetry(String message, int attempt) {
        CompletableFuture<MessageId> future = producer.sendAsync(message);

        return future.handle((msgId, throwable) -> {
            if (throwable == null) {
                return msgId;
            }

            if (isRetriable(throwable) && attempt < MAX_RETRIES) {
                try {
                    Thread.sleep(INITIAL_DELAY_MS * (1L << attempt));
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                    throw new RuntimeException(e);
                }
                return sendWithRetry(message, attempt + 1).join();
            }

            log.error("Failed to send message after {} attempts", attempt + 1, throwable);
            throw new RuntimeException("Send failed", throwable);
        });
    }

    private boolean isRetriable(Throwable throwable) {
        return throwable instanceof PulsarClientException.TimeoutException
            || throwable instanceof PulsarClientException.ConnectException
            || throwable instanceof java.util.concurrent.TimeoutException;
    }

    public void close() throws PulsarClientException {
        if (producer != null) producer.close();
        if (client != null) client.close();
    }
}
```

### Consumer异常处理

**异常类型**：

| 异常类型 | 原因 | 处理策略 | 代码示例 |
|---------|------|----------|----------|
| **PulsarClientException** | 客户端连接失败 | 自动重连 | `connectionTimeoutMs=10000` |
| **TimeoutException** | 接收超时 | 增加超时时间 | `receiveTimeoutMs=1000` |
| **AcknowledgmentException** | 确认失败 | 重试确认或记录日志 | `ackTimeout(30, TimeUnit.SECONDS)` |
| **NegativeAcknowledgmentException** | 否定确认异常 | 检查消息处理逻辑 | `negativeAckRedeliveryDelay(1, TimeUnit.MINUTES)` |
| **ConsumerBusyException** | Consumer繁忙 | 增加Consumer实例或优化处理速度 | 使用Shared订阅模式 |

**Java代码示例**（基于concept06.md）：

```java
// Pulsar Consumer异常处理最佳实践
public class RobustPulsarConsumer {
    private PulsarClient client;
    private Consumer<String> consumer;

    public void initialize() throws PulsarClientException {
        client = PulsarClient.builder()
            .serviceUrl("pulsar://localhost:6650")
            .connectionTimeout(10, TimeUnit.SECONDS)
            .operationTimeout(30, TimeUnit.SECONDS)
            .build();

        consumer = client.newConsumer(Schema.STRING)
            .topic("my-topic")
            .subscriptionName("my-subscription")
            .subscriptionType(SubscriptionType.Shared)
            .ackTimeout(30, TimeUnit.SECONDS)
            .negativeAckRedeliveryDelay(1, TimeUnit.MINUTES)
            .receiverQueueSize(1000)
            .subscribe();
    }

    public void consumeWithErrorHandling() {
        while (true) {
            try {
                Message<String> msg = consumer.receive(1, TimeUnit.SECONDS);
                if (msg == null) continue;

                try {
                    processMessage(msg);
                    consumer.acknowledge(msg);
                } catch (ProcessingException e) {
                    log.error("Failed to process message: {}", e.getMessage());
                    consumer.negativeAcknowledge(msg);
                } catch (FatalException e) {
                    log.error("Fatal error: {}", e.getMessage());
                    consumer.acknowledge(msg);
                }
            } catch (PulsarClientException.TimeoutException e) {
                continue;
            } catch (PulsarClientException e) {
                log.error("Consumer error: {}", e.getMessage(), e);
                handleConsumerError(e);
            } catch (Exception e) {
                log.error("Unexpected error: {}", e.getMessage(), e);
            }
        }
    }

    private void handleConsumerError(PulsarClientException e) {
        if (e instanceof PulsarClientException.NotConnectedException) {
            log.warn("Not connected, waiting for reconnect...");
        } else if (e instanceof PulsarClientException.ConsumerBusyException) {
            log.warn("Consumer busy, consider scaling out");
        }
    }
}
```

### 连接异常处理

**Pulsar连接异常特点**（基于concept06.md）：

- **自动重连机制**：Pulsar客户端内置自动重连，无需手动实现
- **连接池管理**：支持多Broker连接池，自动故障转移
- **健康检查**：定期发送心跳，检测连接健康状态

**Java代码示例**：

```java
// Pulsar连接异常处理配置
PulsarClient client = PulsarClient.builder()
    .serviceUrl("pulsar://broker1:6650,broker2:6650")
    .connectionTimeout(10, TimeUnit.SECONDS)
    .operationTimeout(30, TimeUnit.SECONDS)
    .keepAliveInterval(30, TimeUnit.SECONDS)
    .enableTls(true)
    .tlsTrustCertsFilePath("/path/to/ca.crt")
    .authentication(AuthenticationFactory.token("your-token"))
    .listenerName("internal")
    .build();
```

### Broker异常处理

**Broker无状态设计优势**（基于concept06.md）：

- Broker宕机不影响消息存储（BookKeeper保证）
- Producer/Consumer自动重连到新Broker
- 无需手动故障转移

### BookKeeper异常处理

**BookKeeper异常类型**：

| 异常类型 | 原因 | 处理策略 |
|---------|------|----------|
| **BookieNotAvailableException** | Bookie节点不可用 | 自动切换到其他Bookie |
| **LedgerClosedException** | Ledger已关闭 | 创建新Ledger |
| **NotEnoughBookiesException** | Bookie数量不足 | 增加Bookie节点或降低副本数 |
| **DiskFullException** | 磁盘满 | 清理旧数据或扩容磁盘 |

**BookKeeper自动恢复机制**（基于concept06.md）：

- **Ensemble重选**：当Bookie故障时，自动选择新的Bookie组成Ensemble
- **Ledger恢复**：自动从其他副本恢复故障Ledger的数据
- **数据一致性**：通过Quorum机制（E=3, WQ=2, AQ=2）保证数据一致性

## 1.9.5 容错机制对比矩阵

| 容错维度 | Kafka | MQTT | NATS Core | NATS JetStream | **Pulsar** |
|---------|-------|------|-----------|----------------|------------|
| **连接容错** | 自动重连（客户端） | 自动重连+会话恢复 | 自动重连（多服务器） | 自动重连+Raft恢复 | **自动重连+多Broker故障转移** |
| **消息容错** | 副本机制+ACK | QoS分级保证 | 无（最多一次） | Raft共识+ACK | **BookKeeper Quorum+ACK** |
| **网络分区容错** | CP系统，等待恢复 | 主从切换 | AP系统，继续服务 | CP系统，等待恢复 | **CP系统（BookKeeper Quorum）** |
| **慢消费者容错** | 无保护机制 | 无保护机制 | 自动断开保护 | 自动断开+死信队列 | **自动限流+死信队列** |
| **磁盘满容错** | 拒绝写入 | 丢弃消息 | 无（内存） | 丢弃旧消息或拒绝写入 | **分层存储自动卸载+拒绝写入** |
| **异常恢复时间** | 30秒-2分钟 | 1-3分钟 | 0-5秒 | 1-10秒 | **2秒-1分钟（Broker无状态）** |
| **数据丢失风险** | 低（副本机制） | 中（QoS分级） | 高（无持久化） | 低（Raft共识） | **极低（BookKeeper Quorum）** |
| **Broker故障影响** | 分区不可用（需选举） | Broker级影响 | 节点级影响 | 节点级影响 | **无影响（无状态+自动路由）** |

## 1.9.6 异常处理最佳实践

### 通用最佳实践

1. **重试策略**
   - 指数退避：`wait_time = min(2^retry_count, max_wait)`
   - 最大重试次数：避免无限重试
   - 可重试异常识别：区分可重试和不可重试异常

2. **死信队列**
   - 记录所有处理失败的消息
   - 定期分析和处理死信消息
   - 告警机制：死信消息过多时告警

3. **监控告警**
   - 异常频率监控
   - 异常类型统计
   - 异常恢复时间监控

4. **日志记录**
   - 记录所有异常信息
   - 包含上下文信息（消息ID、时间戳等）
   - 结构化日志便于分析

### Kafka最佳实践

```java
// Kafka异常处理最佳实践
public class KafkaErrorHandler {
    private DeadLetterQueueProducer dlqProducer;

    public void handleException(ConsumerRecord<String, String> record, Exception e) {
        if (e instanceof DeserializationException) {
            // 反序列化异常，发送到死信队列
            dlqProducer.send(record, "DESERIALIZATION_ERROR", e);
        } else if (e instanceof BusinessException) {
            // 业务异常，记录日志
            log.error("Business error for record: {}", record.offset(), e);
        } else {
            // 其他异常，重试或发送到死信队列
            if (isRetriable(e)) {
                throw new RetryableException(e);
            } else {
                dlqProducer.send(record, "UNKNOWN_ERROR", e);
            }
        }
    }
}
```

### MQTT最佳实践

```python
# MQTT异常处理最佳实践
class MQTTErrorHandler:
    def __init__(self):
        self.dlq_client = mqtt.Client()
        self.error_count = {}

    def handle_publish_error(self, topic, payload, error):
        """处理发布错误"""
        error_type = type(error).__name__
        self.error_count[error_type] = self.error_count.get(error_type, 0) + 1

        if self.error_count[error_type] > 10:
            # 错误过多，告警
            send_alert(f"Too many {error_type} errors")

        # 记录到死信队列
        self.dlq_client.publish(f"dlq/{topic}", payload, qos=1)
```

### NATS最佳实践

```go
// NATS异常处理最佳实践
func handleNATSError(nc *nats.Conn, sub *nats.Subscription, err error) {
    switch err {
    case nats.ErrSlowConsumer:
        // 慢消费者，断开连接保护系统
        log.Printf("Slow consumer detected, disconnecting")
        nc.Close()
    case nats.ErrTimeout:
        // 超时，记录但不中断
        log.Printf("Request timeout")
    case nats.ErrNoResponders:
        // 无响应者，记录
        log.Printf("No responders for request")
    default:
        // 其他错误
        log.Printf("Unexpected error: %v", err)
    }
}
```

### Pulsar最佳实践

**1. Producer异常处理最佳实践**（基于concept06.md）：

```java
// Pulsar Producer异常处理最佳实践
public class PulsarProducerBestPractices {
    // 1. 配置合理的超时时间
    Producer<String> producer = client.newProducer(Schema.STRING)
        .topic("my-topic")
        .sendTimeout(30, TimeUnit.SECONDS)      // 发送超时
        .maxPendingMessages(1000)                // 最大待发送消息数
        .blockIfQueueFull(true)                  // 队列满时阻塞，避免消息丢失
        .enableBatching(true)                    // 启用批量发送提升性能
        .create();

    // 2. 使用异步发送+回调处理异常
    producer.sendAsync(message)
        .thenAccept(msgId -> {
            log.info("Message sent: {}", msgId);
        })
        .exceptionally(throwable -> {
            log.error("Send failed", throwable);
            // 记录到死信队列或重试
            handleSendFailure(message, throwable);
            return null;
        });

    // 3. 实现指数退避重试
    private CompletableFuture<MessageId> sendWithRetry(String message, int attempt) {
        return producer.sendAsync(message)
            .handle((msgId, throwable) -> {
                if (throwable == null) return msgId;
                if (isRetriable(throwable) && attempt < MAX_RETRIES) {
                    sleep(INITIAL_DELAY_MS * (1L << attempt));
                    return sendWithRetry(message, attempt + 1).join();
                }
                throw new RuntimeException("Send failed", throwable);
            });
    }
}
```

**2. Consumer异常处理最佳实践**（基于concept06.md）：

```java
// Pulsar Consumer异常处理最佳实践
public class PulsarConsumerBestPractices {
    // 1. 配置合理的ACK超时和重投递延迟
    Consumer<String> consumer = client.newConsumer(Schema.STRING)
        .topic("my-topic")
        .subscriptionName("my-sub")
        .ackTimeout(30, TimeUnit.SECONDS)                    // ACK超时
        .negativeAckRedeliveryDelay(1, TimeUnit.MINUTES)    // 否定确认重投递延迟
        .receiverQueueSize(1000)                             // 接收队列大小
        .maxPendingChunkedMessage(10)                        // 最大待处理分块消息
        .subscribe();

    // 2. 使用消息监听器处理异常
    consumer.messageListener((consumer, msg) -> {
        try {
            processMessage(msg);
            consumer.acknowledge(msg);
        } catch (ProcessingException e) {
            // 处理失败，否定确认（自动重试）
            log.error("Processing failed: {}", e.getMessage());
            consumer.negativeAcknowledge(msg);
        } catch (FatalException e) {
            // 致命错误，确认消息（跳过）
            log.error("Fatal error: {}", e.getMessage());
            consumer.acknowledge(msg);
            // 发送到死信队列
            sendToDLQ(msg, e);
        }
    });

    // 3. 实现死信队列处理
    private void sendToDLQ(Message<String> msg, Exception e) {
        Producer<String> dlqProducer = getDLQProducer();
        dlqProducer.sendAsync(msg.getValue())
            .thenAccept(msgId -> log.info("Sent to DLQ: {}", msgId))
            .exceptionally(throwable -> {
                log.error("Failed to send to DLQ", throwable);
                return null;
            });
    }
}
```

**3. 连接异常处理最佳实践**（基于concept06.md）：

```java
// Pulsar连接异常处理最佳实践
// 1. 配置多Broker连接，自动故障转移
PulsarClient client = PulsarClient.builder()
    .serviceUrl("pulsar://broker1:6650,broker2:6650,broker3:6650")
    .connectionTimeout(10, TimeUnit.SECONDS)
    .operationTimeout(30, TimeUnit.SECONDS)
    .keepAliveInterval(30, TimeUnit.SECONDS)  // 心跳检测
    .build();

// 2. 监听连接状态变化
consumer.connectionListener(new ConnectionListener() {
    @Override
    public void onConnectionChange(ConnectionState state) {
        if (state == ConnectionState.Disconnected) {
            log.warn("Connection lost, will auto-reconnect");
            // 记录指标
            metrics.recordDisconnection();
        } else if (state == ConnectionState.Connected) {
            log.info("Connection restored");
            metrics.recordReconnection();
        }
    }
});
```

**4. 多语言容错模式**（基于concept06.md）：

**Python容错示例**：

```python
# Pulsar Python容错最佳实践
import pulsar
import logging
from typing import Optional
from functools import wraps
import time

def retry_on_failure(max_retries=3, initial_delay=1):
    """重试装饰器"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except (pulsar.Timeout, pulsar.NotConnectedError) as e:
                    if attempt < max_retries - 1:
                        delay = initial_delay * (2 ** attempt)
                        logging.warning(f"Retry {attempt+1}/{max_retries} after {delay}s: {e}")
                        time.sleep(delay)
                    else:
                        logging.error(f"Max retries reached: {e}")
                        raise
                except Exception as e:
                    logging.error(f"Non-retriable error: {e}")
                    raise
            return None
        return wrapper
    return decorator

class RobustPulsarProducer:
    def __init__(self, service_url: str, topic: str):
        self.client = pulsar.Client(
            service_url,
            connection_timeout_ms=10000,
            operation_timeout_seconds=30
        )
        self.producer = self.client.create_producer(
            topic,
            send_timeout_millis=30000,
            max_pending_messages=1000,
            block_if_queue_full=True
        )

    @retry_on_failure(max_retries=3)
    def send(self, message: bytes):
        """带重试的发送"""
        return self.producer.send(message)

    def close(self):
        self.producer.close()
        self.client.close()
```

**Go容错示例**：

```go
// Pulsar Go容错最佳实践
package main

import (
    "context"
    "fmt"
    "log"
    "time"
    "github.com/apache/pulsar-client-go/pulsar"
)

type RetryConfig struct {
    MaxRetries   int
    InitialDelay time.Duration
}

func SendWithRetry(ctx context.Context, producer pulsar.Producer,
                   message []byte, config RetryConfig) (pulsar.MessageID, error) {
    var lastErr error

    for attempt := 0; attempt < config.MaxRetries; attempt++ {
        msgID, err := producer.Send(ctx, &pulsar.ProducerMessage{
            Payload: message,
        })

        if err == nil {
            return msgID, nil
        }

        lastErr = err

        // 判断是否可重试
        if !isRetriable(err) {
            return nil, fmt.Errorf("non-retriable error: %w", err)
        }

        if attempt < config.MaxRetries-1 {
            delay := config.InitialDelay * time.Duration(1<<uint(attempt))
            log.Printf("Retry %d/%d after %v: %v", attempt+1, config.MaxRetries, delay, err)
            time.Sleep(delay)
        }
    }

    return nil, fmt.Errorf("failed after %d attempts: %w", config.MaxRetries, lastErr)
}

func isRetriable(err error) bool {
    // 网络异常、超时异常可重试
    return err == context.DeadlineExceeded
}
```

**Rust容错示例**：

```rust
// Pulsar Rust容错最佳实践
use pulsar::{Error, Producer, Pulsar, TokioExecutor};
use std::time::{Duration, Instant};
use tokio::time::sleep;

pub struct RetryConfig {
    max_retries: u32,
    initial_delay: Duration,
}

impl Default for RetryConfig {
    fn default() -> Self {
        Self {
            max_retries: 3,
            initial_delay: Duration::from_secs(1),
        }
    }
}

impl RobustPulsarProducer {
    pub async fn send_with_retry(
        &mut self,
        message: Vec<u8>,
        config: RetryConfig,
    ) -> Result<(), Error> {
        let mut last_error = None;

        for attempt in 0..config.max_retries {
            match self.producer.send(message.clone()).await {
                Ok(_) => return Ok(()),
                Err(e) => {
                    last_error = Some(e.clone());

                    if !self.is_retriable(&e) {
                        return Err(e);
                    }

                    if attempt < config.max_retries - 1 {
                        let delay = config.initial_delay * (1 << attempt);
                        eprintln!("Retry {}/{} after {:?}: {:?}",
                                 attempt + 1, config.max_retries, delay, e);
                        sleep(delay).await;
                    }
                }
            }
        }

        Err(last_error.unwrap_or_else(||
            Error::Custom("Max retries exceeded".to_string())
        ))
    }

    fn is_retriable(&self, error: &Error) -> bool {
        matches!(error, Error::ConnectionError(_) | Error::Timeout(_))
    }
}
```

**C++容错示例**：

```cpp
// Pulsar C++容错最佳实践
#include <pulsar/Client.h>
#include <pulsar/Producer.h>
#include <iostream>
#include <thread>
#include <chrono>

class RetryConfig {
public:
    int max_retries = 3;
    std::chrono::milliseconds initial_delay{1000};
};

class RobustPulsarProducer {
public:
    pulsar::Result sendWithRetry(const std::string& message,
                                  const RetryConfig& config) {
        pulsar::Message msg = pulsar::MessageBuilder()
            .setContent(message)
            .build();

        pulsar::Result last_result = pulsar::ResultUnknownError;

        for (int attempt = 0; attempt < config.max_retries; ++attempt) {
            pulsar::Result result = producer_.send(msg);

            if (result == pulsar::ResultOk) {
                return pulsar::ResultOk;
            }

            last_result = result;

            if (!isRetriable(result)) {
                return result;
            }

            if (attempt < config.max_retries - 1) {
                auto delay = config.initial_delay * (1 << attempt);
                std::cerr << "Retry " << (attempt + 1) << "/"
                          << config.max_retries << " after "
                          << delay.count() << "ms: "
                          << result.str() << std::endl;
                std::this_thread::sleep_for(delay);
            }
        }

        return last_result;
    }

private:
    bool isRetriable(pulsar::Result result) {
        return result == pulsar::ResultTimeout ||
               result == pulsar::ResultConnectError ||
               result == pulsar::ResultNotConnected;
    }
};
```

---

## 1.9.6 异常处理参考资源

### 异常处理理论

- **容错系统设计**: [Fault Tolerance](https://en.wikipedia.org/wiki/Fault_tolerance)
- **错误处理模式**: [Error Handling Patterns](https://martinfowler.com/articles/replaceThrowWithNotification.html)
- **重试模式**: [Retry Pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/retry)

### 技术参考

- **Kafka异常处理**: [Kafka Error Handling](https://kafka.apache.org/documentation/#design_guarantees)
- **MQTT异常处理**: [MQTT Error Handling](https://docs.oasis-open.org/mqtt/mqtt/v5.0/mqtt-v5.0.html#_Toc3901031)
- **NATS异常处理**: [NATS Error Handling](https://docs.nats.io/using-nats/developer/connecting/errors)
- **Pulsar异常处理**: [Pulsar Error Handling](https://pulsar.apache.org/docs/client-libraries-java/#error-handling)
- **BookKeeper异常处理**: [BookKeeper Error Handling](https://bookkeeper.apache.org/docs/latest/bookkeeperOverview/#fault-tolerance)

---

**参考来源**:

- 基于concept01.md、concept03.md、concept06.md内容整理
- Kafka、MQTT、NATS、Pulsar官方文档中的异常处理说明
- **Pulsar开发架构与程序设计深度论证（concept06.md）**：存算分离的技术实现、API设计哲学、多语言支持、性能优化编程模式
- 容错系统设计理论和最佳实践
- 生产环境异常处理经验

**最后更新**: 2025-12-31
