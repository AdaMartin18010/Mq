# 2.6 异常场景与容错设计

## 目录

- [2.6 异常场景与容错设计](#26-异常场景与容错设计)
  - [目录](#目录)
  - [2.6.1 异常场景分类](#261-异常场景分类)
    - [异常类型矩阵](#异常类型矩阵)
    - [异常严重程度分级](#异常严重程度分级)
  - [2.6.2 日志聚合场景异常处理](#262-日志聚合场景异常处理)
    - [Kafka日志聚合异常场景](#kafka日志聚合异常场景)
  - [2.6.3 IoT设备场景异常处理](#263-iot设备场景异常处理)
    - [MQTT IoT异常场景](#mqtt-iot异常场景)
  - [2.6.4 微服务通信场景异常处理](#264-微服务通信场景异常处理)
    - [NATS微服务异常场景](#nats微服务异常场景)
  - [2.6.5 容错设计模式](#265-容错设计模式)
    - [1. 重试模式（Retry Pattern）](#1-重试模式retry-pattern)
    - [2. 熔断器模式（Circuit Breaker Pattern）](#2-熔断器模式circuit-breaker-pattern)
    - [3. 超时模式（Timeout Pattern）](#3-超时模式timeout-pattern)
    - [4. 降级模式（Fallback Pattern）](#4-降级模式fallback-pattern)
  - [2.6.6 异常恢复策略](#266-异常恢复策略)
    - [恢复策略矩阵](#恢复策略矩阵)
    - [恢复时间目标（RTO）](#恢复时间目标rto)
    - [恢复点目标（RPO）](#恢复点目标rpo)
  - [2.6.7 异常处理参考资源](#267-异常处理参考资源)
    - [容错设计参考](#容错设计参考)
    - [异常处理参考](#异常处理参考)

---

## 2.6.1 异常场景分类

### 异常类型矩阵

| 异常类型 | 影响范围 | 严重程度 | Kafka | MQTT | NATS |
|---------|----------|----------|-------|------|------|
| **网络异常** | 连接中断 | 高 | 自动重连 | 自动重连+会话恢复 | 自动重连 |
| **节点故障** | 部分/全部服务不可用 | 高 | ISR机制恢复 | 主从切换 | 自动故障转移 |
| **消息丢失** | 数据完整性 | 中-高 | 副本机制保护 | QoS分级保护 | Core模式无保护 |
| **消息重复** | 数据一致性 | 中 | 幂等性保证 | QoS 2保证 | Core模式可能重复 |
| **消息积压** | 延迟增加 | 中 | Consumer Lag | 无保护 | 慢消费者保护 |
| **资源耗尽** | 服务拒绝 | 高 | 磁盘满拒绝写入 | 内存溢出 | 自动限流保护 |
| **配置错误** | 功能异常 | 中 | 需重启 | 需重启 | 热加载 |

### 异常严重程度分级

**P0 - 严重（Critical）**：

- 服务完全不可用
- 数据丢失风险
- 需要立即处理

**P1 - 高（High）**：

- 部分功能不可用
- 性能严重下降
- 需要尽快处理

**P2 - 中（Medium）**：

- 功能降级
- 性能轻微下降
- 可以延迟处理

**P3 - 低（Low）**：

- 轻微影响
- 可以忽略或记录

## 2.6.2 日志聚合场景异常处理

### Kafka日志聚合异常场景

**场景1: Producer批量发送失败**

```java
// 异常场景：网络抖动导致批量发送失败
public class RobustLogProducer {
    private KafkaProducer<String, String> producer;
    private DeadLetterQueue dlq;

    public void sendLogBatch(List<LogRecord> records) {
        List<ProducerRecord<String, String>> kafkaRecords = new ArrayList<>();

        for (LogRecord record : records) {
            kafkaRecords.add(new ProducerRecord<>("logs", record.toJson()));
        }

        // 批量发送
        for (ProducerRecord<String, String> record : kafkaRecords) {
            producer.send(record, new Callback() {
                @Override
                public void onCompletion(RecordMetadata metadata, Exception exception) {
                    if (exception != null) {
                        // 发送失败，记录到死信队列
                        if (exception instanceof RetriableException) {
                            // 可重试异常，记录但继续
                            log.warn("Retriable error, will retry", exception);
                        } else {
                            // 不可重试异常，发送到死信队列
                            dlq.send(record);
                            log.error("Non-retriable error, sent to DLQ", exception);
                        }
                    }
                }
            });
        }

        // 刷新所有未完成的请求
        producer.flush();
    }
}
```

**场景2: Consumer处理异常**

```java
// 异常场景：日志解析失败或存储失败
public class RobustLogConsumer {
    private KafkaConsumer<String, String> consumer;
    private LogStorage storage;
    private ErrorCounter errorCounter;

    public void consumeLogs() {
        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));

            for (ConsumerRecord<String, String> record : records) {
                try {
                    // 解析日志
                    LogRecord logRecord = parseLog(record.value());

                    // 存储日志
                    storage.save(logRecord);

                } catch (ParseException e) {
                    // 解析异常，记录错误但继续处理
                    errorCounter.increment("parse_error");
                    log.warn("Failed to parse log: {}", record.value(), e);

                    // 记录原始消息到错误日志
                    saveErrorLog(record.value(), e);

                } catch (StorageException e) {
                    // 存储异常，可能需要重试
                    if (isRetriable(e)) {
                        // 不提交offset，等待重试
                        log.warn("Storage error, will retry", e);
                        continue;  // 不提交，下次重新消费
                    } else {
                        // 不可重试，记录到死信队列
                        errorCounter.increment("storage_error");
                        dlq.send(record);
                        log.error("Non-retriable storage error", e);
                    }
                }
            }

            // 只有所有消息处理成功才提交offset
            consumer.commitSync();
        }
    }
}
```

**场景3: Broker磁盘满异常**

```bash
# 异常场景：Broker磁盘满，拒绝写入
# 检测脚本
#!/bin/bash
DISK_USAGE=$(df -h /kafka-logs | awk 'NR==2 {print $5}' | sed 's/%//')

if [ $DISK_USAGE -gt 90 ]; then
    # 磁盘使用率超过90%，告警
    send_alert "Kafka disk usage critical: ${DISK_USAGE}%"

    # 清理旧日志
    kafka-log-retention.sh --delete-old-logs --retention-hours 24

    # 如果还是满，扩容磁盘
    if [ $(df -h /kafka-logs | awk 'NR==2 {print $5}' | sed 's/%//') -gt 90 ]; then
        scale_disk_capacity
    fi
fi
```

## 2.6.3 IoT设备场景异常处理

### MQTT IoT异常场景

**场景1: 设备批量重连风暴**

```python
# 异常场景：网络恢复后，大量设备同时重连
class IoTReconnectController:
    def __init__(self):
        self.reconnect_times = {}  # 记录每个设备的重连时间
        self.max_reconnects_per_minute = 10  # 每分钟最多10次重连

    def on_connect(self, client, userdata, flags, rc):
        """连接控制，防止重连风暴"""
        device_id = userdata.get('device_id')
        now = time.time()

        # 检查重连频率
        if device_id in self.reconnect_times:
            recent_reconnects = [
                t for t in self.reconnect_times[device_id]
                if now - t < 60  # 最近1分钟
            ]

            if len(recent_reconnects) >= self.max_reconnects_per_minute:
                # 重连过于频繁，拒绝连接
                client.disconnect()
                log.warn(f"Device {device_id} reconnecting too frequently")
                return

        # 记录重连时间
        if device_id not in self.reconnect_times:
            self.reconnect_times[device_id] = []
        self.reconnect_times[device_id].append(now)

        # 清理旧记录（保留最近1小时）
        self.reconnect_times[device_id] = [
            t for t in self.reconnect_times[device_id]
            if now - t < 3600
        ]

        # 正常处理连接
        log.info(f"Device {device_id} connected")
```

**场景2: 设备消息丢失处理**

```python
# 异常场景：设备网络不稳定，消息可能丢失
class IoTMessageHandler:
    def __init__(self):
        self.pending_messages = {}  # 待确认消息
        self.message_timeout = 30  # 30秒超时

    def send_control_command(self, device_id, command, qos=1):
        """发送控制指令，带重试机制"""
        msg_id = f"{device_id}_{int(time.time())}"

        # 使用QoS 1保证至少一次投递
        result = self.client.publish(
            f"devices/{device_id}/command",
            json.dumps(command),
            qos=qos
        )

        if result.rc == mqtt.MQTT_ERR_SUCCESS:
            # 等待PUBACK确认
            if qos == 1:
                self.pending_messages[msg_id] = {
                    'command': command,
                    'timestamp': time.time(),
                    'retries': 0
                }

                # 启动超时检查
                threading.Timer(
                    self.message_timeout,
                    self.check_message_timeout,
                    args=[msg_id]
                ).start()
        else:
            # 发布失败，重试
            self.retry_publish(device_id, command, msg_id)

    def check_message_timeout(self, msg_id):
        """检查消息超时"""
        if msg_id in self.pending_messages:
            msg = self.pending_messages[msg_id]
            if time.time() - msg['timestamp'] > self.message_timeout:
                # 超时未收到确认，重试
                if msg['retries'] < 3:
                    msg['retries'] += 1
                    self.retry_publish(
                        msg['device_id'],
                        msg['command'],
                        msg_id
                    )
                else:
                    # 重试次数超限，告警
                    log.error(f"Message {msg_id} failed after 3 retries")
                    send_alert(f"Device command failed: {msg_id}")
                    del self.pending_messages[msg_id]
```

**场景3: Broker内存溢出异常**

```python
# 异常场景：大量设备订阅导致内存溢出
class IoTBrokerController:
    def __init__(self):
        self.max_subscriptions = 100000  # 最大订阅数
        self.max_memory_mb = 4096  # 最大内存4GB
        self.current_subscriptions = 0

    def on_subscribe(self, client, userdata, mid, granted_qos):
        """订阅控制"""
        self.current_subscriptions += 1

        # 检查订阅数限制
        if self.current_subscriptions > self.max_subscriptions:
            log.warn("Subscription limit reached, rejecting new subscriptions")
            # 拒绝新订阅或清理旧订阅

        # 检查内存使用
        memory_usage = self.get_memory_usage()
        if memory_usage > self.max_memory_mb:
            log.error("Memory limit exceeded, cleaning up old subscriptions")
            self.cleanup_old_subscriptions()

    def cleanup_old_subscriptions(self):
        """清理旧订阅"""
        # 清理非活跃设备的订阅
        inactive_devices = self.get_inactive_devices()
        for device_id in inactive_devices:
            self.unsubscribe_device(device_id)
            self.current_subscriptions -= 1
```

## 2.6.4 微服务通信场景异常处理

### NATS微服务异常场景

**场景1: 服务调用超时**

```go
// 异常场景：服务响应超时
func callServiceWithTimeout(nc *nats.Conn, subject string, request []byte, timeout time.Duration) ([]byte, error) {
    // 创建请求-响应
    msg, err := nc.Request(subject, request, timeout)
    if err != nil {
        if err == nats.ErrTimeout {
            // 超时异常，记录并重试或降级
            log.Warn("Service call timeout, using fallback")
            return fallbackService(request)
        } else if err == nats.ErrNoResponders {
            // 无响应者，服务可能不可用
            log.Error("No responders available, service may be down")
            return nil, fmt.Errorf("service unavailable: %w", err)
        }
        return nil, err
    }

    return msg.Data, nil
}

func fallbackService(request []byte) ([]byte, error) {
    // 降级服务：返回默认值或缓存数据
    return []byte("default_response"), nil
}
```

**场景2: 消息处理异常**

```go
// 异常场景：消息处理失败
func setupRobustSubscriber(nc *nats.Conn) {
    sub, _ := nc.Subscribe("service.request", func(msg *nats.Msg) {
        defer func() {
            if r := recover(); r != nil {
                // 捕获panic，防止程序崩溃
                log.Printf("Panic in message handler: %v", r)

                // 发送错误响应
                errorResponse := createErrorResponse(r)
                msg.Respond(errorResponse)
            }
        }()

        // 处理消息
        response, err := processRequest(msg.Data)
        if err != nil {
            // 处理错误
            log.Printf("Error processing request: %v", err)

            // 根据错误类型处理
            if isRetriableError(err) {
                // 可重试错误，返回错误但不ACK（JetStream模式）
                return
            } else {
                // 不可重试错误，返回错误响应
                errorResponse := createErrorResponse(err)
                msg.Respond(errorResponse)
            }
            return
        }

        // 处理成功，返回响应
        msg.Respond(response)
    })
}
```

**场景3: 慢消费者保护**

```go
// 异常场景：消费者处理慢，导致消息积压
func setupSlowConsumerProtection(nc *nats.Conn) {
    // 设置慢消费者保护
    nc.SetErrorHandler(func(nc *nats.Conn, sub *nats.Subscription, err error) {
        if err == nats.ErrSlowConsumer {
            // 慢消费者，断开连接保护系统
            pendingMsgs, pendingBytes, _ := sub.Pending()

            log.Printf("Slow consumer detected: %d msgs, %d bytes pending",
                pendingMsgs, pendingBytes)

            // 断开连接，触发重连
            nc.Close()

            // 告警
            sendAlert("Slow consumer detected and disconnected")
        }
    })

    // 设置待处理消息限制
    sub, _ := nc.Subscribe("subject", handler)
    sub.SetPendingLimits(1000, 10*1024*1024)  // 1000条或10MB
}
```

## 2.6.5 容错设计模式

### 1. 重试模式（Retry Pattern）

**实现**：

```java
// 重试模式实现
public class RetryHandler {
    private static final int MAX_RETRIES = 3;
    private static final long INITIAL_DELAY = 1000;  // 1秒

    public <T> T executeWithRetry(Supplier<T> operation) {
        int retries = 0;
        long delay = INITIAL_DELAY;

        while (retries < MAX_RETRIES) {
            try {
                return operation.get();
            } catch (RetriableException e) {
                retries++;
                if (retries >= MAX_RETRIES) {
                    throw new MaxRetriesExceededException(e);
                }

                // 指数退避
                try {
                    Thread.sleep(delay);
                    delay *= 2;  // 指数退避
                } catch (InterruptedException ie) {
                    Thread.currentThread().interrupt();
                    throw new RuntimeException(ie);
                }
            }
        }

        throw new MaxRetriesExceededException();
    }
}
```

### 2. 熔断器模式（Circuit Breaker Pattern）

**实现**：

```java
// 熔断器模式实现
public class CircuitBreaker {
    private enum State { CLOSED, OPEN, HALF_OPEN }

    private State state = State.CLOSED;
    private int failureCount = 0;
    private int successCount = 0;
    private final int failureThreshold = 5;
    private final int successThreshold = 2;
    private final long timeout = 60000;  // 60秒
    private long lastFailureTime = 0;

    public <T> T execute(Supplier<T> operation) {
        if (state == State.OPEN) {
            if (System.currentTimeMillis() - lastFailureTime > timeout) {
                state = State.HALF_OPEN;  // 进入半开状态
            } else {
                throw new CircuitBreakerOpenException();
            }
        }

        try {
            T result = operation.get();
            onSuccess();
            return result;
        } catch (Exception e) {
            onFailure();
            throw e;
        }
    }

    private void onSuccess() {
        failureCount = 0;
        if (state == State.HALF_OPEN) {
            successCount++;
            if (successCount >= successThreshold) {
                state = State.CLOSED;  // 关闭熔断器
                successCount = 0;
            }
        }
    }

    private void onFailure() {
        failureCount++;
        lastFailureTime = System.currentTimeMillis();

        if (failureCount >= failureThreshold) {
            state = State.OPEN;  // 打开熔断器
        }
    }
}
```

### 3. 超时模式（Timeout Pattern）

**实现**：

```java
// 超时模式实现
public class TimeoutHandler {
    public <T> T executeWithTimeout(Supplier<T> operation, long timeoutMs) {
        ExecutorService executor = Executors.newSingleThreadExecutor();
        Future<T> future = executor.submit(operation::get);

        try {
            return future.get(timeoutMs, TimeUnit.MILLISECONDS);
        } catch (TimeoutException e) {
            future.cancel(true);
            throw new OperationTimeoutException("Operation timed out", e);
        } catch (ExecutionException e) {
            throw new RuntimeException(e.getCause());
        } finally {
            executor.shutdown();
        }
    }
}
```

### 4. 降级模式（Fallback Pattern）

**实现**：

```java
// 降级模式实现
public class FallbackHandler {
    public <T> T executeWithFallback(Supplier<T> primary, Supplier<T> fallback) {
        try {
            return primary.get();
        } catch (Exception e) {
            log.warn("Primary operation failed, using fallback", e);
            try {
                return fallback.get();
            } catch (Exception fallbackError) {
                log.error("Fallback also failed", fallbackError);
                throw new FallbackFailedException(fallbackError);
            }
        }
    }
}
```

## 2.6.6 异常恢复策略

### 恢复策略矩阵

| 异常类型 | 恢复策略 | Kafka | MQTT | NATS |
|---------|----------|-------|------|------|
| **网络中断** | 自动重连 | ✅ 支持 | ✅ 支持+会话恢复 | ✅ 支持 |
| **节点故障** | 故障转移 | ✅ ISR机制 | ✅ 主从切换 | ✅ 自动切换 |
| **消息丢失** | 重发机制 | ✅ 副本机制 | ✅ QoS重发 | ❌ Core无保护 |
| **消息重复** | 幂等处理 | ✅ 幂等性 | ✅ QoS 2 | ⚠️ 需应用层处理 |
| **消息积压** | 扩容处理 | ✅ 增加Consumer | ⚠️ 需手动扩容 | ✅ 自动保护 |
| **资源耗尽** | 资源限制 | ⚠️ 需手动配置 | ⚠️ 需手动配置 | ✅ 自动限流 |

### 恢复时间目标（RTO）

| 系统 | RTO目标 | 实际RTO | 自动化程度 |
|------|---------|---------|-----------|
| **Kafka** | < 2分钟 | 30秒-2分钟 | 部分自动化 |
| **MQTT** | < 3分钟 | 1-3分钟 | 部分自动化 |
| **NATS** | < 10秒 | 0-5秒 | 完全自动化 |

### 恢复点目标（RPO）

| 系统 | RPO目标 | 实际RPO | 数据保护机制 |
|------|---------|---------|-------------|
| **Kafka** | 0数据丢失 | 0（ISR机制） | 副本机制 |
| **MQTT** | < 1分钟 | 0（QoS 2） | QoS分级 |
| **NATS Core** | 无要求 | 无保护 | 无持久化 |
| **NATS JetStream** | 0数据丢失 | 0（Raft） | Raft共识 |

---

## 2.6.7 异常处理参考资源

### 容错设计参考

- **容错模式**: [Fault Tolerance Patterns](https://martinfowler.com/articles/reliability.html)
- **重试模式**: [Retry Pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/retry)
- **熔断器模式**: [Circuit Breaker Pattern](https://martinfowler.com/bliki/CircuitBreaker.html)
- **超时模式**: [Timeout Pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/timeout)

### 异常处理参考

- **Kafka异常处理**: [Kafka Error Handling](https://kafka.apache.org/documentation/#design_guarantees)
- **MQTT异常处理**: [MQTT Error Handling](https://docs.oasis-open.org/mqtt/mqtt/v5.0/mqtt-v5.0.html#_Toc3901031)
- **NATS异常处理**: [NATS Error Handling](https://docs.nats.io/using-nats/developer/connecting/errors)

---

**参考来源**:

- 基于concept02.md和concept03.md内容整理
- 容错设计模式和最佳实践
- Kafka、MQTT、NATS官方文档中的异常处理说明
- 生产环境异常处理经验

**最后更新**: 2025-12-31
